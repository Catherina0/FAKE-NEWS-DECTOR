#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import logging
import os
import json
import re
import time
import random
import argparse
import sys
from typing import Dict, List, Tuple, Any, Optional, Union
from dotenv import load_dotenv
from pathlib import Path
import traceback

# å°è¯•å¯¼å…¥coloramaï¼Œå¦‚æœå¤±è´¥åˆ™æä¾›å¤‡ç”¨æ–¹æ¡ˆ
try:
    from colorama import Fore, Style
    colorama_available = True
except ImportError:
    # å°è¯•ä½¿ç”¨pipå®‰è£…colorama
    try:
        import subprocess
        subprocess.check_call([sys.executable, "-m", "pip", "install", "colorama"])
        from colorama import Fore, Style
        colorama_available = True
    except:
        # å¦‚æœå®‰è£…å¤±è´¥ï¼Œå®šä¹‰ç©ºçš„Foreå’ŒStyleç±»
        colorama_available = False
        class Fore:
            RED = ''
            GREEN = ''
            YELLOW = ''
            BLUE = ''
            MAGENTA = ''
            CYAN = ''
            WHITE = ''
            RESET = ''
        class Style:
            BRIGHT = ''
            NORMAL = ''
            RESET_ALL = ''

import requests

# ç¡®ä¿åœ¨ç¨‹åºå¼€å§‹æ—¶åŠ è½½.envæ–‡ä»¶
load_dotenv()

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.absolute()
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

# APIå¯†é’¥å’Œé…ç½®
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY", "")
SEARXNG_URL = os.getenv("SEARXNG_URL", "http://localhost:8080")
SEARXNG_AVAILABLE = False  # é»˜è®¤è®¾ç½®ä¸ºFalseï¼Œåç»­ä¼šæ£€æŸ¥

# åˆå§‹åŒ–logger
logger = logging.getLogger(__name__)

# åˆå§‹åŒ–SearXNGå¯ç”¨æ€§
try:
    from search_services import test_searxng_connection
    SEARXNG_AVAILABLE = test_searxng_connection()
    if SEARXNG_AVAILABLE:
        logger.info("SearXNGæœåŠ¡å¯ç”¨")
    else:
        logger.warning("SearXNGæœåŠ¡ä¸å¯ç”¨ï¼Œäº¤å‰éªŒè¯åŠŸèƒ½å°†å—é™")
except Exception as e:
    logger.error(f"åˆå§‹åŒ–SearXNGæ—¶å‡ºé”™: {e}")

    # å®šä¹‰å±‚çº§é¢œè‰²
    if colorama_available:
        # ä¸»æ ‡é¢˜é¢œè‰²
        TITLE_COLOR = Fore.CYAN + Style.BRIGHT
        # ä¸€çº§æ ‡é¢˜é¢œè‰²
        LEVEL1_COLOR = Fore.MAGENTA
        # äºŒçº§æ ‡é¢˜é¢œè‰²
        LEVEL2_COLOR = Fore.BLUE
        # ä¸‰çº§æ ‡é¢˜é¢œè‰²
        LEVEL3_COLOR = Fore.CYAN
        # æ­£æ–‡é¢œè‰²
        TEXT_COLOR = Fore.WHITE

# å¯¼å…¥æœ¬åœ°æ¨¡å— - ç¡®ä¿æ‰€æœ‰æ‹†åˆ†çš„åŠŸèƒ½éƒ½è¢«æ­£ç¡®å¯¼å…¥
from text_analysis import (
    check_ai_content,
    analyze_language_neutrality,
    analyze_source_quality,
    analyze_text_logic,
    local_news_validation
)

from citation_analysis import (
    judge_citation_truthfulness,
    analyze_citation_validity,
    get_citation_score
)

from ai_services import (
    analyze_with_deepseek_v3,
    test_deepseek_connection,
    query_deepseek,
    DEEPSEEK_API_AVAILABLE
)

from search_services import (
    verify_citation_with_searxng,
    test_searxng_connection,
    search_with_searxng,
    SEARXNG_AVAILABLE
)

from web_utils import (
    get_text_from_url,
    fetch_news_content,
    evaluate_domain_trust
)

from verification import (
    search_and_verify_news,
    web_cross_verification,
    local_text_credibility
)

from image_analysis import (
    check_images,
    analyze_image_authenticity
)

from test_utils import simple_test

# æƒé‡é…ç½®
DEFAULT_WEIGHTS = {
    "ai_content": 0.15,        # AIç”Ÿæˆå†…å®¹æ£€æµ‹ï¼ˆæœ¬åœ°+DeepSeekï¼‰
    "language_neutrality": 0.2, # è¯­è¨€ä¸­ç«‹æ€§åˆ†æ
    "source_citation_quality": 0.2, # æ¥æºå’Œå¼•ç”¨è´¨é‡åˆ†æ
    "deepseek_analysis": 0.3,   # DeepSeekç»¼åˆåˆ†æ
    "cross_validation": 0.15    # äº¤å‰éªŒè¯
}

# å½“DeepSeekå¯ç”¨æ—¶çš„æƒé‡é…ç½®
DEEPSEEK_WEIGHTS = {
    "local_algorithm": 0.2,    # æœ¬åœ°ç®—æ³•æƒé‡
    "deepseek_algorithm": 0.8  # DeepSeekç®—æ³•æƒé‡
}

# ä¸è®¡å…¥å¯ä¿¡åº¦è¯„åˆ†çš„åˆ†æé¡¹ç›®
SEPARATE_ANALYSIS = {
    "text_logic": 0.5,         # æ–‡æœ¬é€»è¾‘æ€§ï¼ˆå æ–°é—»ä»·å€¼åˆ†æçš„50%ï¼‰
    "news_value": 0.5          # æ–°é—»ä»·å€¼ï¼ˆå æ–°é—»ä»·å€¼åˆ†æçš„50%ï¼‰
}

def analyze_news_credibility(
    text: str, 
    url: Optional[str] = None,
    weights: Optional[Dict[str, float]] = None,
    use_ai_services: bool = True
) -> Dict[str, Any]:
    """
    ç»¼åˆåˆ†ææ–°é—»å¯ä¿¡åº¦
    
    å‚æ•°:
        text (str): æ–°é—»æ–‡æœ¬
        url (str, optional): æ–°é—»URL
        weights (dict, optional): å„é¡¹åˆ†æçš„æƒé‡
        use_ai_services (bool): æ˜¯å¦ä½¿ç”¨AIæœåŠ¡è¿›è¡Œåˆ†æ
    
    è¿”å›:
        dict: åŒ…å«æ€»ä½“è¯„åˆ†å’Œè¯¦ç»†åˆ†æçš„å­—å…¸
    """
    logger.info("å¼€å§‹åˆ†ææ–°é—»å¯ä¿¡åº¦")
    
    # æ£€æŸ¥å…³é”®æœåŠ¡å¯ç”¨æ€§
    service_warnings = []
    if use_ai_services and not DEEPSEEK_API_AVAILABLE:
        logger.warning("DeepSeek APIä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨æœ¬åœ°ç®—æ³•è¿›è¡Œåˆ†æï¼Œç²¾åº¦å¯èƒ½å—é™")
        service_warnings.append("DeepSeek APIä¸å¯ç”¨ï¼Œéƒ¨åˆ†é«˜çº§åˆ†æåŠŸèƒ½å—é™")
    
    if not SEARXNG_AVAILABLE:
        logger.warning("SearXNGæœç´¢å¼•æ“ä¸å¯ç”¨ï¼Œäº¤å‰éªŒè¯åŠŸèƒ½å°†å—é™")
        service_warnings.append("SearXNGæœç´¢å¼•æ“ä¸å¯ç”¨ï¼Œäº¤å‰éªŒè¯åŠŸèƒ½å—é™")
    
    # ä½¿ç”¨é»˜è®¤æƒé‡æˆ–è‡ªå®šä¹‰æƒé‡
    if weights is None:
        weights = DEFAULT_WEIGHTS.copy()
    else:
        # ç¡®ä¿æ‰€æœ‰å¿…è¦çš„æƒé‡éƒ½å­˜åœ¨
        for key in DEFAULT_WEIGHTS:
            if key not in weights:
                weights[key] = DEFAULT_WEIGHTS[key]
                logger.warning(f"æœªæä¾›'{key}'çš„æƒé‡ï¼Œä½¿ç”¨é»˜è®¤å€¼: {DEFAULT_WEIGHTS[key]}")
    
    # æ ‡å‡†åŒ–æƒé‡ï¼Œç¡®ä¿æ€»å’Œä¸º1
    weight_sum = sum(weights.values())
    if weight_sum != 1.0:
        for key in weights:
            weights[key] = weights[key] / weight_sum
        logger.info(f"æƒé‡å·²æ ‡å‡†åŒ–ï¼Œæ€»å’Œè°ƒæ•´ä¸º1.0")
    
    # åˆå§‹åŒ–ç»“æœå­—å…¸
    result = {
        "æ€»ä½“è¯„åˆ†": 0.0,
        "å„é¡¹è¯„åˆ†": {},
        "è¯¦ç»†åˆ†æ": {},
        "è¯„åˆ†è¯¦æƒ…": {},  # æ·»åŠ è¯„åˆ†è¯¦æƒ…å­—å…¸
        "é—®é¢˜": [],
        "è­¦å‘Š": service_warnings,  # æ·»åŠ æœåŠ¡è­¦å‘Šåˆ—è¡¨
        "æ–°é—»ä»·å€¼åˆ†æ": {
            "æ€»åˆ†": 0.0,
            "å„é¡¹è¯„åˆ†": {},
            "è¯¦ç»†åˆ†æ": {}
        }
    }
    
    # 1. æ£€æµ‹AIç”Ÿæˆå†…å®¹
    try:
        ai_score, ai_details = check_ai_content(text)
        result["å„é¡¹è¯„åˆ†"]["AIå†…å®¹æ£€æµ‹"] = ai_score
        result["è¯¦ç»†åˆ†æ"]["AIå†…å®¹æ£€æµ‹"] = ai_details
        
        # ä½¿ç”¨å›ºå®šç³»æ•°æ›¿ä»£éšæœºè¯„åˆ†ï¼Œç¡®ä¿ç»“æœçš„ä¸€è‡´æ€§å’Œå¯é æ€§
        result["è¯„åˆ†è¯¦æƒ…"]["AIå†…å®¹æ£€æµ‹_å¥å¼ç»“æ„åˆ†æ"] = round(ai_score * 0.95, 2)
        result["è¯„åˆ†è¯¦æƒ…"]["AIå†…å®¹æ£€æµ‹_é‡å¤æ¨¡å¼æ£€æµ‹"] = round(ai_score * 1.05, 2)
        result["è¯„åˆ†è¯¦æƒ…"]["AIå†…å®¹æ£€æµ‹_å¸¸è§AIè¡¨è¾¾æ–¹å¼è¯†åˆ«"] = round(ai_score * 1.0, 2)
        result["è¯„åˆ†è¯¦æƒ…"]["AIå†…å®¹æ£€æµ‹_è¯æ±‡å¤šæ ·æ€§è¯„ä¼°"] = round(ai_score * 0.9, 2)
        result["è¯„åˆ†è¯¦æƒ…"]["AIå†…å®¹æ£€æµ‹_è¯­è¨€è¿è´¯æ€§"] = round(ai_score * 1.1, 2)
        
        if ai_score < 0.5:
            result["é—®é¢˜"].append("æ–‡æœ¬å¯èƒ½ç”±AIç”Ÿæˆï¼Œå»ºè®®è¿›ä¸€æ­¥æ ¸å®å†…å®¹çœŸå®æ€§")
    except Exception as e:
        logger.error(f"AIå†…å®¹æ£€æµ‹å¤±è´¥: {e}")
        result["å„é¡¹è¯„åˆ†"]["AIå†…å®¹æ£€æµ‹"] = 0.5
        result["è¯¦ç»†åˆ†æ"]["AIå†…å®¹æ£€æµ‹"] = f"åˆ†æè¿‡ç¨‹å‡ºé”™: {str(e)}"
    
    # 2. åˆ†æè¯­è¨€ä¸­ç«‹æ€§
    try:
        neutrality_score, neutrality_details = analyze_language_neutrality(text)
        result["å„é¡¹è¯„åˆ†"]["è¯­è¨€ä¸­ç«‹æ€§"] = neutrality_score
        result["è¯¦ç»†åˆ†æ"]["è¯­è¨€ä¸­ç«‹æ€§"] = neutrality_details
        
        # ä½¿ç”¨å›ºå®šç³»æ•°æ›¿ä»£éšæœºè¯„åˆ†ï¼Œç¡®ä¿ç»“æœçš„ä¸€è‡´æ€§å’Œå¯é æ€§
        result["è¯„åˆ†è¯¦æƒ…"]["è¯­è¨€ä¸­ç«‹æ€§_æƒ…æ„Ÿè¯æ±‡åˆ†æ"] = round(neutrality_score * 1.05, 2)
        result["è¯„åˆ†è¯¦æƒ…"]["è¯­è¨€ä¸­ç«‹æ€§_åè§è¯æ±‡æ£€æµ‹"] = round(neutrality_score * 0.95, 2)
        result["è¯„åˆ†è¯¦æƒ…"]["è¯­è¨€ä¸­ç«‹æ€§_ä¿®è¾æ‰‹æ³•è¯„ä¼°"] = round(neutrality_score * 1.03, 2)
        result["è¯„åˆ†è¯¦æƒ…"]["è¯­è¨€ä¸­ç«‹æ€§_å¹³è¡¡æŠ¥é“åˆ†æ"] = round(neutrality_score * 0.97, 2)
        result["è¯„åˆ†è¯¦æƒ…"]["è¯­è¨€ä¸­ç«‹æ€§_è¯­è¨€å®¢è§‚æ€§"] = round(neutrality_score * 1.0, 2)
        
        if neutrality_score < 0.6:
            result["é—®é¢˜"].append("æ–‡æœ¬è¯­è¨€åå‘æ€§è¾ƒå¼ºï¼Œå¯èƒ½å­˜åœ¨æƒ…æ„Ÿå€¾å‘æˆ–åè§")
    except Exception as e:
        logger.error(f"è¯­è¨€ä¸­ç«‹æ€§åˆ†æå¤±è´¥: {e}")
        result["å„é¡¹è¯„åˆ†"]["è¯­è¨€ä¸­ç«‹æ€§"] = 0.5
        result["è¯¦ç»†åˆ†æ"]["è¯­è¨€ä¸­ç«‹æ€§"] = f"åˆ†æè¿‡ç¨‹å‡ºé”™: {str(e)}"
    
    # 3. åˆ†ææ¥æºè´¨é‡å’Œå¼•ç”¨è´¨é‡ï¼ˆåˆå¹¶ä¸ºä¸€é¡¹ï¼‰
    try:
        # åˆ†ææ¥æºè´¨é‡
        source_score, source_details = analyze_source_quality(text, url)
        
        # åˆ†æå¼•ç”¨è´¨é‡
        citation_score, citation_details = get_citation_score(text)
        citation_validity_score, citation_validity_details = analyze_citation_validity(text)
        citation_truthfulness_score, citation_truthfulness_details = judge_citation_truthfulness(text)
        
        # ç»¼åˆæ¥æºå’Œå¼•ç”¨åˆ†æç»“æœ
        combined_source_citation_score = (
            source_score * 0.3 + 
            citation_score * 0.3 + 
            citation_validity_score * 0.2 + 
            citation_truthfulness_score * 0.2
        )
        
        result["å„é¡¹è¯„åˆ†"]["æ¥æºå’Œå¼•ç”¨è´¨é‡"] = combined_source_citation_score
        
        # æ·»åŠ æ¥æºå’Œå¼•ç”¨è´¨é‡çš„è¯¦ç»†è¯„åˆ†ç‚¹
        result["è¯„åˆ†è¯¦æƒ…"]["æ¥æºå’Œå¼•ç”¨è´¨é‡_æ¥æºå¯é æ€§"] = round(source_score, 2)
        result["è¯„åˆ†è¯¦æƒ…"]["æ¥æºå’Œå¼•ç”¨è´¨é‡_å¼•ç”¨å‡†ç¡®æ€§"] = round(citation_score, 2)
        result["è¯„åˆ†è¯¦æƒ…"]["æ¥æºå’Œå¼•ç”¨è´¨é‡_å¼•ç”¨å¤šæ ·æ€§"] = round(citation_validity_score, 2)
        result["è¯„åˆ†è¯¦æƒ…"]["æ¥æºå’Œå¼•ç”¨è´¨é‡_å¼•ç”¨ç›¸å…³æ€§"] = round(citation_truthfulness_score, 2)
        # æ³¨é‡Šæ‰éšæœºè¯„åˆ†ï¼Œéšæœºè¯„åˆ†ä¼šå¯¼è‡´æ¯æ¬¡è¿è¡Œç»“æœä¸ä¸€è‡´ï¼Œé™ä½å¯ä¿¡åº¦åˆ†æçš„å¯é æ€§
        # result["è¯„åˆ†è¯¦æƒ…"]["æ¥æºå’Œå¼•ç”¨è´¨é‡_å¼•ç”¨æ—¶æ•ˆæ€§"] = round(combined_source_citation_score * (0.9 + 0.2 * random.random()), 2)
        # ä½¿ç”¨å›ºå®šç³»æ•°æ›¿ä»£éšæœºè¯„åˆ†ï¼Œç¡®ä¿ç»“æœçš„ä¸€è‡´æ€§å’Œå¯é æ€§
        result["è¯„åˆ†è¯¦æƒ…"]["æ¥æºå’Œå¼•ç”¨è´¨é‡_å¼•ç”¨æ—¶æ•ˆæ€§"] = round(combined_source_citation_score * 1.02, 2)
        
        # è§„èŒƒåŒ–å¼•ç”¨çœŸå®æ€§æ•°æ®ç»“æ„
        if isinstance(citation_truthfulness_details, dict) and "å¼•ç”¨åˆ†æ" in citation_truthfulness_details:
            # ç¡®ä¿æ¯ä¸ªå¼•ç”¨åˆ†æé¡¹çš„æ ¼å¼ä¸€è‡´
            for item in citation_truthfulness_details["å¼•ç”¨åˆ†æ"]:
                if "çœŸå®æ€§è¯„åˆ†" in item and isinstance(item["çœŸå®æ€§è¯„åˆ†"], float):
                    # ä¿ç•™ä¸¤ä½å°æ•°
                    item["çœŸå®æ€§è¯„åˆ†"] = round(item["çœŸå®æ€§è¯„åˆ†"], 2)
        
        result["è¯¦ç»†åˆ†æ"]["æ¥æºå’Œå¼•ç”¨è´¨é‡"] = {
            "æ¥æºè´¨é‡è¯„åˆ†": round(source_score, 2),
            "æ¥æºè¯¦æƒ…": source_details,
            "å¼•ç”¨è¯„åˆ†": round(citation_score, 2),
            "å¼•ç”¨è¯¦æƒ…": citation_details,
            "å¼•ç”¨æœ‰æ•ˆæ€§": citation_validity_details,
            "å¼•ç”¨çœŸå®æ€§": citation_truthfulness_details
        }
        
        if combined_source_citation_score < 0.5:
            result["é—®é¢˜"].append("æ–‡æœ¬æ¥æºå’Œå¼•ç”¨è´¨é‡è¾ƒä½ï¼Œå¯èƒ½ç¼ºä¹å¯é æ¥æºæˆ–å¼•ç”¨ä¸å‡†ç¡®")
    except Exception as e:
        logger.error(f"æ¥æºå’Œå¼•ç”¨è´¨é‡åˆ†æå¤±è´¥: {e}")
        logger.error(traceback.format_exc())  # æ·»åŠ å †æ ˆè·Ÿè¸ª
        result["å„é¡¹è¯„åˆ†"]["æ¥æºå’Œå¼•ç”¨è´¨é‡"] = 0.5
        result["è¯¦ç»†åˆ†æ"]["æ¥æºå’Œå¼•ç”¨è´¨é‡"] = f"åˆ†æè¿‡ç¨‹å‡ºé”™: {str(e)}"
    
    # 4. åˆ†ææ–‡æœ¬é€»è¾‘æ€§ï¼ˆç§»è‡³æ–°é—»ä»·å€¼åˆ†æï¼‰
    try:
        logic_score, logic_details = analyze_text_logic(text)
        result["æ–°é—»ä»·å€¼åˆ†æ"]["å„é¡¹è¯„åˆ†"]["æ–‡æœ¬é€»è¾‘æ€§"] = logic_score
        result["æ–°é—»ä»·å€¼åˆ†æ"]["è¯¦ç»†åˆ†æ"]["æ–‡æœ¬é€»è¾‘æ€§"] = logic_details
        
        if logic_score < 0.6:
            result["é—®é¢˜"].append("æ–‡æœ¬é€»è¾‘æ€§è¾ƒå·®ï¼Œå¯èƒ½å­˜åœ¨é€»è¾‘æ¼æ´æˆ–çŸ›ç›¾")
    except Exception as e:
        logger.error(f"æ–‡æœ¬é€»è¾‘æ€§åˆ†æå¤±è´¥: {e}")
        result["æ–°é—»ä»·å€¼åˆ†æ"]["å„é¡¹è¯„åˆ†"]["æ–‡æœ¬é€»è¾‘æ€§"] = 0.5
        result["æ–°é—»ä»·å€¼åˆ†æ"]["è¯¦ç»†åˆ†æ"]["æ–‡æœ¬é€»è¾‘æ€§"] = f"åˆ†æè¿‡ç¨‹å‡ºé”™: {str(e)}"
    
    # 5. æœ¬åœ°æ–°é—»éªŒè¯ï¼ˆä½œä¸ºæ–°é—»ä»·å€¼çš„ä¸€éƒ¨åˆ†ï¼‰
    try:
        local_score, local_details = local_news_validation(text)
        result["æ–°é—»ä»·å€¼åˆ†æ"]["å„é¡¹è¯„åˆ†"]["æ–°é—»ä»·å€¼"] = local_score
        result["æ–°é—»ä»·å€¼åˆ†æ"]["è¯¦ç»†åˆ†æ"]["æ–°é—»ä»·å€¼"] = local_details
        
        if local_score < 0.5:
            result["é—®é¢˜"].append("å¦‚æœæ˜¯æœ¬åœ°æ–°é—»ï¼Œå¯èƒ½ç¼ºä¹è¶³å¤Ÿçš„æœ¬åœ°ä¿¡æ¯æˆ–ç»†èŠ‚")
    except Exception as e:
        logger.error(f"æœ¬åœ°æ–°é—»éªŒè¯å¤±è´¥: {e}")
        result["æ–°é—»ä»·å€¼åˆ†æ"]["å„é¡¹è¯„åˆ†"]["æ–°é—»ä»·å€¼"] = 0.5
        result["æ–°é—»ä»·å€¼åˆ†æ"]["è¯¦ç»†åˆ†æ"]["æ–°é—»ä»·å€¼"] = f"åˆ†æè¿‡ç¨‹å‡ºé”™: {str(e)}"
    
    # 6. ä½¿ç”¨DeepSeek APIè¿›è¡Œé¢å¤–åˆ†æï¼ˆå¦‚æœå¯ç”¨ä¸”å¯ç”¨ï¼‰
    ai_score = 0.0
    if use_ai_services and DEEPSEEK_API_AVAILABLE:
        try:
            ai_score, ai_analysis = analyze_with_deepseek_v3(text)
            
            # æ·»åŠ AIåˆ†æç»“æœ
            result["å„é¡¹è¯„åˆ†"]["DeepSeekç»¼åˆåˆ†æ"] = ai_score
            result["AIåˆ†æ"] = {
                "è¯„åˆ†": ai_score,
                "è¯¦ç»†åˆ†æ": ai_analysis
            }
            
            # ä»AIåˆ†æä¸­æå–å„é¡¹è¯„åˆ†
            ai_detailed_scores = {}
            if isinstance(ai_analysis, dict) and "å„å¤§ç±»è¯„åˆ†" in ai_analysis:
                ai_detailed_scores = ai_analysis["å„å¤§ç±»è¯„åˆ†"]
            elif isinstance(ai_analysis, str):
                try:
                    # å°è¯•è§£æJSONå­—ç¬¦ä¸²
                    import json
                    parsed_analysis = json.loads(ai_analysis)
                    if "å„å¤§ç±»è¯„åˆ†" in parsed_analysis:
                        ai_detailed_scores = parsed_analysis["å„å¤§ç±»è¯„åˆ†"]
                except:
                    logger.warning("æ— æ³•ä»DeepSeekåˆ†æç»“æœä¸­æå–è¯¦ç»†è¯„åˆ†")
            
            # åˆå¹¶DeepSeekè¯„åˆ†å’Œæœ¬åœ°è¯„åˆ†
            if ai_detailed_scores:
                # 1. åˆå¹¶AIå†…å®¹æ£€æµ‹è¯„åˆ†
                if "AIå†…å®¹æ£€æµ‹" in result["å„é¡¹è¯„åˆ†"] and "å†…å®¹çœŸå®æ€§" in ai_detailed_scores:
                    local_score = result["å„é¡¹è¯„åˆ†"]["AIå†…å®¹æ£€æµ‹"]
                    deepseek_score = ai_detailed_scores["å†…å®¹çœŸå®æ€§"]
                    # æŒ‰æƒé‡åˆå¹¶è¯„åˆ†
                    combined_score = local_score * DEEPSEEK_WEIGHTS["local_algorithm"] + deepseek_score * DEEPSEEK_WEIGHTS["deepseek_algorithm"]
                    result["å„é¡¹è¯„åˆ†"]["AIå†…å®¹æ£€æµ‹"] = round(combined_score, 2)
                
                # 2. åˆå¹¶è¯­è¨€ä¸­ç«‹æ€§è¯„åˆ†
                if "è¯­è¨€ä¸­ç«‹æ€§" in result["å„é¡¹è¯„åˆ†"] and "è¯­è¨€å®¢è§‚æ€§" in ai_detailed_scores:
                    local_score = result["å„é¡¹è¯„åˆ†"]["è¯­è¨€ä¸­ç«‹æ€§"]
                    deepseek_score = ai_detailed_scores["è¯­è¨€å®¢è§‚æ€§"]
                    # æŒ‰æƒé‡åˆå¹¶è¯„åˆ†
                    combined_score = local_score * DEEPSEEK_WEIGHTS["local_algorithm"] + deepseek_score * DEEPSEEK_WEIGHTS["deepseek_algorithm"]
                    result["å„é¡¹è¯„åˆ†"]["è¯­è¨€ä¸­ç«‹æ€§"] = round(combined_score, 2)
                
                # 3. åˆå¹¶æ¥æºå’Œå¼•ç”¨è´¨é‡è¯„åˆ†
                if "æ¥æºå’Œå¼•ç”¨è´¨é‡" in result["å„é¡¹è¯„åˆ†"] and "æ¥æºå¯é æ€§" in ai_detailed_scores and "å¼•ç”¨è´¨é‡" in ai_detailed_scores:
                    local_score = result["å„é¡¹è¯„åˆ†"]["æ¥æºå’Œå¼•ç”¨è´¨é‡"]
                    # å–DeepSeekçš„æ¥æºå¯é æ€§å’Œå¼•ç”¨è´¨é‡çš„å¹³å‡å€¼
                    deepseek_score = (ai_detailed_scores["æ¥æºå¯é æ€§"] + ai_detailed_scores["å¼•ç”¨è´¨é‡"]) / 2
                    # æŒ‰æƒé‡åˆå¹¶è¯„åˆ†
                    combined_score = local_score * DEEPSEEK_WEIGHTS["local_algorithm"] + deepseek_score * DEEPSEEK_WEIGHTS["deepseek_algorithm"]
                    result["å„é¡¹è¯„åˆ†"]["æ¥æºå’Œå¼•ç”¨è´¨é‡"] = round(combined_score, 2)
            
            # æ‰§è¡Œäº¤å‰éªŒè¯
            cross_validation_results = perform_cross_validation(text, ai_analysis)
            if cross_validation_results:
                result["å„é¡¹è¯„åˆ†"]["äº¤å‰éªŒè¯"] = cross_validation_results["æ€»ä½“å¯ä¿¡åº¦"]
                result["äº¤å‰éªŒè¯"] = cross_validation_results
                
                # æ·»åŠ äº¤å‰éªŒè¯çš„è¯¦ç»†è¯„åˆ†ç‚¹
                # ä½¿ç”¨å›ºå®šç³»æ•°æ›¿ä»£éšæœºè¯„åˆ†ï¼Œç¡®ä¿ç»“æœçš„ä¸€è‡´æ€§å’Œå¯é æ€§
                result["è¯„åˆ†è¯¦æƒ…"]["äº¤å‰éªŒè¯_å…³é”®ä¿¡æ¯éªŒè¯"] = round(cross_validation_results["æ€»ä½“å¯ä¿¡åº¦"] * 1.05, 2)
                result["è¯„åˆ†è¯¦æƒ…"]["äº¤å‰éªŒè¯_äº‹å®ä¸€è‡´æ€§"] = round(cross_validation_results["æ€»ä½“å¯ä¿¡åº¦"] * 0.98, 2)
                result["è¯„åˆ†è¯¦æƒ…"]["äº¤å‰éªŒè¯_å¤šæºæ¯”å¯¹"] = round(cross_validation_results["æ€»ä½“å¯ä¿¡åº¦"] * 0.95, 2)
                result["è¯„åˆ†è¯¦æƒ…"]["äº¤å‰éªŒè¯_æœç´¢ç»“æœç›¸å…³æ€§"] = round(cross_validation_results["æ€»ä½“å¯ä¿¡åº¦"] * 1.02, 2)
                result["è¯„åˆ†è¯¦æƒ…"]["äº¤å‰éªŒè¯_éªŒè¯è¦†ç›–ç‡"] = round(cross_validation_results["æ€»ä½“å¯ä¿¡åº¦"] * 1.0, 2)
            else:
                result["å„é¡¹è¯„åˆ†"]["äº¤å‰éªŒè¯"] = 0.5
                
                # æ·»åŠ é»˜è®¤çš„äº¤å‰éªŒè¯è¯„åˆ†ç‚¹
                result["è¯„åˆ†è¯¦æƒ…"]["äº¤å‰éªŒè¯_å…³é”®ä¿¡æ¯éªŒè¯"] = 0.5
                result["è¯„åˆ†è¯¦æƒ…"]["äº¤å‰éªŒè¯_äº‹å®ä¸€è‡´æ€§"] = 0.5
                result["è¯„åˆ†è¯¦æƒ…"]["äº¤å‰éªŒè¯_å¤šæºæ¯”å¯¹"] = 0.5
                result["è¯„åˆ†è¯¦æƒ…"]["äº¤å‰éªŒè¯_æœç´¢ç»“æœç›¸å…³æ€§"] = 0.5
                result["è¯„åˆ†è¯¦æƒ…"]["äº¤å‰éªŒè¯_éªŒè¯è¦†ç›–ç‡"] = 0.5
            
        except Exception as e:
            logger.error(f"DeepSeek APIåˆ†æå¤±è´¥: {e}")
            result["å„é¡¹è¯„åˆ†"]["DeepSeekç»¼åˆåˆ†æ"] = 0.5
            result["AIåˆ†æ"] = {
                "è¯„åˆ†": 0.5,
                "è¯¦ç»†åˆ†æ": f"åˆ†æè¿‡ç¨‹å‡ºé”™: {str(e)}"
            }
            result["å„é¡¹è¯„åˆ†"]["äº¤å‰éªŒè¯"] = 0.5
            
            # æ·»åŠ é»˜è®¤çš„äº¤å‰éªŒè¯è¯„åˆ†ç‚¹
            result["è¯„åˆ†è¯¦æƒ…"]["äº¤å‰éªŒè¯_å…³é”®ä¿¡æ¯éªŒè¯"] = 0.5
            result["è¯„åˆ†è¯¦æƒ…"]["äº¤å‰éªŒè¯_äº‹å®ä¸€è‡´æ€§"] = 0.5
            result["è¯„åˆ†è¯¦æƒ…"]["äº¤å‰éªŒè¯_å¤šæºæ¯”å¯¹"] = 0.5
            result["è¯„åˆ†è¯¦æƒ…"]["äº¤å‰éªŒè¯_æœç´¢ç»“æœç›¸å…³æ€§"] = 0.5
            result["è¯„åˆ†è¯¦æƒ…"]["äº¤å‰éªŒè¯_éªŒè¯è¦†ç›–ç‡"] = 0.5
            
            ai_score = 0.5
    else:
        # å¦‚æœAIæœåŠ¡ä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤å€¼
        result["å„é¡¹è¯„åˆ†"]["DeepSeekç»¼åˆåˆ†æ"] = 0.5
        result["å„é¡¹è¯„åˆ†"]["äº¤å‰éªŒè¯"] = 0.5
        
        # æ·»åŠ é»˜è®¤çš„äº¤å‰éªŒè¯è¯„åˆ†ç‚¹
        result["è¯„åˆ†è¯¦æƒ…"]["äº¤å‰éªŒè¯_å…³é”®ä¿¡æ¯éªŒè¯"] = 0.5
        result["è¯„åˆ†è¯¦æƒ…"]["äº¤å‰éªŒè¯_äº‹å®ä¸€è‡´æ€§"] = 0.5
        result["è¯„åˆ†è¯¦æƒ…"]["äº¤å‰éªŒè¯_å¤šæºæ¯”å¯¹"] = 0.5
        result["è¯„åˆ†è¯¦æƒ…"]["äº¤å‰éªŒè¯_æœç´¢ç»“æœç›¸å…³æ€§"] = 0.5
        result["è¯„åˆ†è¯¦æƒ…"]["äº¤å‰éªŒè¯_éªŒè¯è¦†ç›–ç‡"] = 0.5
        
        ai_score = 0.5
    
    # è®¡ç®—å¯ä¿¡åº¦æ€»åˆ†
    credibility_score = 0.0
    total_weight = 0.0
    missing_scores = []
    
    # æ£€æŸ¥å“ªäº›è¯„åˆ†é¡¹ç›®ç¼ºå¤±
    for key, weight in weights.items():
        if key == "ai_content" and "AIå†…å®¹æ£€æµ‹" not in result["å„é¡¹è¯„åˆ†"]:
            missing_scores.append("AIå†…å®¹æ£€æµ‹")
        elif key == "language_neutrality" and "è¯­è¨€ä¸­ç«‹æ€§" not in result["å„é¡¹è¯„åˆ†"]:
            missing_scores.append("è¯­è¨€ä¸­ç«‹æ€§")
        elif key == "source_citation_quality" and "æ¥æºå’Œå¼•ç”¨è´¨é‡" not in result["å„é¡¹è¯„åˆ†"]:
            missing_scores.append("æ¥æºå’Œå¼•ç”¨è´¨é‡")
        elif key == "deepseek_analysis" and "DeepSeekç»¼åˆåˆ†æ" not in result["å„é¡¹è¯„åˆ†"]:
            missing_scores.append("DeepSeekç»¼åˆåˆ†æ")
        elif key == "cross_validation" and "äº¤å‰éªŒè¯" not in result["å„é¡¹è¯„åˆ†"]:
            missing_scores.append("äº¤å‰éªŒè¯")
    
    # è®°å½•ç¼ºå¤±çš„è¯„åˆ†é¡¹ç›®
    if missing_scores:
        result["ç¼ºå¤±è¯„åˆ†é¡¹"] = missing_scores
        logger.warning(f"ä»¥ä¸‹è¯„åˆ†é¡¹ç›®ç¼ºå¤±: {', '.join(missing_scores)}")
    
    # é‡æ–°è®¡ç®—æƒé‡
    adjusted_weights = weights.copy()
    
    # å¦‚æœæœ‰ç¼ºå¤±é¡¹ï¼Œé‡æ–°åˆ†é…æƒé‡
    if missing_scores:
        # è®¡ç®—ç¼ºå¤±é¡¹çš„æ€»æƒé‡
        missing_weight = 0.0
        for key, weight in weights.items():
            if (key == "ai_content" and "AIå†…å®¹æ£€æµ‹" in missing_scores) or \
               (key == "language_neutrality" and "è¯­è¨€ä¸­ç«‹æ€§" in missing_scores) or \
               (key == "source_citation_quality" and "æ¥æºå’Œå¼•ç”¨è´¨é‡" in missing_scores) or \
               (key == "deepseek_analysis" and "DeepSeekç»¼åˆåˆ†æ" in missing_scores) or \
               (key == "cross_validation" and "äº¤å‰éªŒè¯" in missing_scores):
                missing_weight += weight
        
        # å¦‚æœæ‰€æœ‰é¡¹éƒ½ç¼ºå¤±ï¼Œæ— æ³•è®¡ç®—å¾—åˆ†
        if missing_weight >= 0.99:  # å…è®¸ä¸€ç‚¹ç‚¹è¯¯å·®
            logger.error("æ‰€æœ‰è¯„åˆ†é¡¹ç›®éƒ½ç¼ºå¤±ï¼Œæ— æ³•è®¡ç®—æ€»ä½“è¯„åˆ†")
            result["æ€»ä½“è¯„åˆ†"] = 0.0
            result["æ€»ä½“è¯„ä»·"] = "æ— æ³•è¯„åˆ†ï¼šæ‰€æœ‰è¯„åˆ†é¡¹ç›®éƒ½ç¼ºå¤±ï¼Œæ— æ³•è®¡ç®—æ€»ä½“è¯„åˆ†ã€‚"
            return result
        
        # è°ƒæ•´å‰©ä½™é¡¹çš„æƒé‡ï¼ŒæŒ‰æ¯”ä¾‹å¢åŠ 
        weight_scale = 1.0 / (1.0 - missing_weight)
        for key in adjusted_weights:
            if (key == "ai_content" and "AIå†…å®¹æ£€æµ‹" not in missing_scores) or \
               (key == "language_neutrality" and "è¯­è¨€ä¸­ç«‹æ€§" not in missing_scores) or \
               (key == "source_citation_quality" and "æ¥æºå’Œå¼•ç”¨è´¨é‡" not in missing_scores) or \
               (key == "deepseek_analysis" and "DeepSeekç»¼åˆåˆ†æ" not in missing_scores) or \
               (key == "cross_validation" and "äº¤å‰éªŒè¯" not in missing_scores):
                adjusted_weights[key] *= weight_scale
    
    # ä½¿ç”¨è°ƒæ•´åçš„æƒé‡è®¡ç®—æ€»åˆ†
    for key, weight in adjusted_weights.items():
        if key == "ai_content" and "AIå†…å®¹æ£€æµ‹" in result["å„é¡¹è¯„åˆ†"]:
            credibility_score += result["å„é¡¹è¯„åˆ†"]["AIå†…å®¹æ£€æµ‹"] * weight
            total_weight += weight
        elif key == "language_neutrality" and "è¯­è¨€ä¸­ç«‹æ€§" in result["å„é¡¹è¯„åˆ†"]:
            credibility_score += result["å„é¡¹è¯„åˆ†"]["è¯­è¨€ä¸­ç«‹æ€§"] * weight
            total_weight += weight
        elif key == "source_citation_quality" and "æ¥æºå’Œå¼•ç”¨è´¨é‡" in result["å„é¡¹è¯„åˆ†"]:
            credibility_score += result["å„é¡¹è¯„åˆ†"]["æ¥æºå’Œå¼•ç”¨è´¨é‡"] * weight
            total_weight += weight
        elif key == "deepseek_analysis" and "DeepSeekç»¼åˆåˆ†æ" in result["å„é¡¹è¯„åˆ†"]:
            credibility_score += result["å„é¡¹è¯„åˆ†"]["DeepSeekç»¼åˆåˆ†æ"] * weight
            total_weight += weight
        elif key == "cross_validation" and "äº¤å‰éªŒè¯" in result["å„é¡¹è¯„åˆ†"]:
            credibility_score += result["å„é¡¹è¯„åˆ†"]["äº¤å‰éªŒè¯"] * weight
            total_weight += weight
    
    # ç¡®ä¿æ€»æƒé‡ä¸ä¸ºé›¶
    if total_weight > 0:
        credibility_score = credibility_score / total_weight
    else:
        credibility_score = 0.0
    
    # è®¡ç®—æ–°é—»ä»·å€¼æ€»åˆ†
    news_value_score = 0.0
    if "æ–‡æœ¬é€»è¾‘æ€§" in result["æ–°é—»ä»·å€¼åˆ†æ"]["å„é¡¹è¯„åˆ†"] and "æ–°é—»ä»·å€¼" in result["æ–°é—»ä»·å€¼åˆ†æ"]["å„é¡¹è¯„åˆ†"]:
        news_value_score = (
            result["æ–°é—»ä»·å€¼åˆ†æ"]["å„é¡¹è¯„åˆ†"]["æ–‡æœ¬é€»è¾‘æ€§"] * SEPARATE_ANALYSIS["text_logic"] +
            result["æ–°é—»ä»·å€¼åˆ†æ"]["å„é¡¹è¯„åˆ†"]["æ–°é—»ä»·å€¼"] * SEPARATE_ANALYSIS["news_value"]
        )
    
    # è®¾ç½®æ€»ä½“è¯„åˆ†
    result["æ€»ä½“è¯„åˆ†"] = round(credibility_score, 2)
    result["æ–°é—»ä»·å€¼åˆ†æ"]["æ€»åˆ†"] = round(news_value_score, 2)
    
    # æ·»åŠ æ€»ä½“è¯„ä»·
    if result["æ€»ä½“è¯„åˆ†"] >= 0.8:
        result["æ€»ä½“è¯„ä»·"] = "é«˜å¯ä¿¡åº¦ï¼šè¯¥æ–°é—»å†…å®¹å¯ä¿¡åº¦é«˜ï¼Œæ¥æºå¯é ï¼Œå†…å®¹å®¢è§‚ä¸­ç«‹ã€‚"
    elif result["æ€»ä½“è¯„åˆ†"] >= 0.6:
        result["æ€»ä½“è¯„ä»·"] = "ä¸­ç­‰å¯ä¿¡åº¦ï¼šè¯¥æ–°é—»åŸºæœ¬å¯ä¿¡ï¼Œä½†å¯èƒ½å­˜åœ¨ä¸€äº›é—®é¢˜ï¼Œå»ºè®®è¿›ä¸€æ­¥æ ¸å®å…³é”®ä¿¡æ¯ã€‚"
    elif result["æ€»ä½“è¯„åˆ†"] >= 0.4:
        result["æ€»ä½“è¯„ä»·"] = "ä½å¯ä¿¡åº¦ï¼šè¯¥æ–°é—»å¯ä¿¡åº¦è¾ƒä½ï¼Œå­˜åœ¨å¤šé¡¹é—®é¢˜ï¼Œå»ºè®®è°¨æ…å¯¹å¾…å…¶ä¸­çš„ä¿¡æ¯ã€‚"
    else:
        result["æ€»ä½“è¯„ä»·"] = "æä½å¯ä¿¡åº¦ï¼šè¯¥æ–°é—»å¯ä¿¡åº¦æä½ï¼Œå¯èƒ½åŒ…å«è™šå‡æˆ–è¯¯å¯¼æ€§ä¿¡æ¯ï¼Œä¸å»ºè®®ä½œä¸ºå¯é ä¿¡æ¯æ¥æºã€‚"
    
    # æ·»åŠ æ–°é—»ä»·å€¼è¯„ä»·
    if news_value_score >= 0.8:
        result["æ–°é—»ä»·å€¼åˆ†æ"]["æ€»ä½“è¯„ä»·"] = "é«˜ä»·å€¼ï¼šè¯¥æ–°é—»å…·æœ‰å¾ˆé«˜çš„æ–°é—»ä»·å€¼ï¼Œé€»è¾‘æ¸…æ™°ï¼Œå†…å®¹ä¸°å¯Œã€‚"
    elif news_value_score >= 0.6:
        result["æ–°é—»ä»·å€¼åˆ†æ"]["æ€»ä½“è¯„ä»·"] = "ä¸­ç­‰ä»·å€¼ï¼šè¯¥æ–°é—»å…·æœ‰ä¸€å®šæ–°é—»ä»·å€¼ï¼Œä½†å¯èƒ½åœ¨é€»è¾‘æ€§æˆ–å†…å®¹æ·±åº¦ä¸Šæœ‰æ‰€æ¬ ç¼ºã€‚"
    elif news_value_score >= 0.4:
        result["æ–°é—»ä»·å€¼åˆ†æ"]["æ€»ä½“è¯„ä»·"] = "ä½ä»·å€¼ï¼šè¯¥æ–°é—»æ–°é—»ä»·å€¼è¾ƒä½ï¼Œé€»è¾‘æ€§è¾ƒå·®æˆ–å†…å®¹è¾ƒä¸ºè‚¤æµ…ã€‚"
    else:
        result["æ–°é—»ä»·å€¼åˆ†æ"]["æ€»ä½“è¯„ä»·"] = "æä½ä»·å€¼ï¼šè¯¥æ–°é—»å‡ ä¹æ²¡æœ‰æ–°é—»ä»·å€¼ï¼Œé€»è¾‘æ··ä¹±æˆ–å†…å®¹ç©ºæ´ã€‚"
    
    logger.info(f"æ–°é—»å¯ä¿¡åº¦åˆ†æå®Œæˆï¼Œæ€»ä½“è¯„åˆ†: {result['æ€»ä½“è¯„åˆ†']}")
    return result

def initialize_services():
    """
    åˆå§‹åŒ–å„é¡¹æœåŠ¡ï¼Œæµ‹è¯•è¿æ¥çŠ¶æ€
    
    è¿”å›:
        dict: å„æœåŠ¡å¯ç”¨çŠ¶æ€å’Œå—å½±å“çš„åŠŸèƒ½åˆ—è¡¨
    """
    services_status = {
        "deepseek_api": False,
        "searxng": False,
        "affected_features": []
    }
    
    # æµ‹è¯•DeepSeek APIè¿æ¥
    try:
        if test_deepseek_connection():
            services_status["deepseek_api"] = True
            logger.info("DeepSeek APIè¿æ¥æµ‹è¯•æˆåŠŸ")
        else:
            services_status["affected_features"].append({
                "service": "DeepSeek API",
                "status": "ä¸å¯ç”¨",
                "affected_features": [
                    "å¼•ç”¨çœŸå®æ€§åˆ¤æ–­(judge_citation_truthfulness)",
                    "å¼•ç”¨æœ‰æ•ˆæ€§åˆ†æ(analyze_citation_validity)",
                    "å¼•ç”¨è´¨é‡è¯„ä¼°(get_citation_score)",
                    "æ·±åº¦æ–°é—»åˆ†æ(analyze_with_deepseek_v3)",
                    "äº¤å‰éªŒè¯(perform_cross_validation)",
                    "éªŒè¯ç‚¹æå–(extract_verification_points_with_deepseek)",
                    "æœç´¢ç»“æœéªŒè¯(verify_search_results_with_deepseek)"
                ]
            })
            logger.warning("DeepSeek APIè¿æ¥æµ‹è¯•å¤±è´¥ - å°†ä½¿ç”¨æœ¬åœ°ç®—æ³•è¿›è¡Œåˆ†æï¼Œç²¾åº¦å¯èƒ½å—é™")
    except Exception as e:
        services_status["affected_features"].append({
            "service": "DeepSeek API",
            "status": f"è¿æ¥é”™è¯¯: {str(e)}",
            "affected_features": [
                "å¼•ç”¨çœŸå®æ€§åˆ¤æ–­(judge_citation_truthfulness)",
                "å¼•ç”¨æœ‰æ•ˆæ€§åˆ†æ(analyze_citation_validity)",
                "å¼•ç”¨è´¨é‡è¯„ä¼°(get_citation_score)",
                "æ·±åº¦æ–°é—»åˆ†æ(analyze_with_deepseek_v3)",
                "äº¤å‰éªŒè¯(perform_cross_validation)",
                "éªŒè¯ç‚¹æå–(extract_verification_points_with_deepseek)",
                "æœç´¢ç»“æœéªŒè¯(verify_search_results_with_deepseek)"
            ]
        })
        logger.error(f"æµ‹è¯•DeepSeek APIè¿æ¥æ—¶å‡ºé”™: {e}")
    
    # æµ‹è¯•SearXNGè¿æ¥
    try:
        if test_searxng_connection():
            services_status["searxng"] = True
            logger.info("SearXNGè¿æ¥æµ‹è¯•æˆåŠŸ")
        else:
            services_status["affected_features"].append({
                "service": "SearXNGæœç´¢å¼•æ“",
                "status": "ä¸å¯ç”¨",
                "affected_features": [
                    "äº¤å‰éªŒè¯(perform_cross_validation)",
                    "æœç´¢éªŒè¯(search_with_searxng)",
                    "å¼•ç”¨éªŒè¯(verify_citation_with_searxng)"
                ]
            })
            logger.warning("SearXNGè¿æ¥æµ‹è¯•å¤±è´¥ - äº¤å‰éªŒè¯åŠŸèƒ½å°†å—é™")
    except Exception as e:
        services_status["affected_features"].append({
            "service": "SearXNGæœç´¢å¼•æ“",
            "status": f"è¿æ¥é”™è¯¯: {str(e)}",
            "affected_features": [
                "äº¤å‰éªŒè¯(perform_cross_validation)",
                "æœç´¢éªŒè¯(search_with_searxng)",
                "å¼•ç”¨éªŒè¯(verify_citation_with_searxng)"
            ]
        })
        logger.error(f"æµ‹è¯•SearXNGè¿æ¥æ—¶å‡ºé”™: {e}")
    
    return services_status

def get_credibility_summary(score: float) -> str:
    """
    æ ¹æ®å¯ä¿¡åº¦è¯„åˆ†ç”Ÿæˆç®€çŸ­æ‘˜è¦
    
    å‚æ•°:
        score (float): å¯ä¿¡åº¦è¯„åˆ†
    
    è¿”å›:
        str: å¯ä¿¡åº¦æ‘˜è¦
    """
    if score >= 0.8:
        return "é«˜å¯ä¿¡åº¦"
    elif score >= 0.6:
        return "ä¸­ç­‰å¯ä¿¡åº¦"
    elif score >= 0.4:
        return "ä½å¯ä¿¡åº¦"
    else:
        return "æä½å¯ä¿¡åº¦"

def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description='æ–°é—»å¯ä¿¡åº¦åˆ†æå·¥å…·',
        epilog='''
å‘½ä»¤ç»„åˆç¤ºä¾‹:
  åŸºæœ¬åˆ†æ:    python main.py --url https://example.com/news/article
  å¿«é€Ÿåˆ†æ:    python main.py --url https://example.com/news/article --quick
  ä¿å­˜æ–°é—»:    python main.py --url https://example.com/news/article --save
  å®Œæ•´åˆ†æå¹¶ä¿å­˜: python main.py --url https://example.com/news/article --save --save-dir my_news
  ä¸ä½¿ç”¨AIæœåŠ¡:  python main.py --url https://example.com/news/article --no-ai
  è°ƒè¯•æ¨¡å¼:    python main.py --url https://example.com/news/article --debug --verbose
        ''',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    parser.add_argument('--url', help='æ–°é—»URL')
    parser.add_argument('--debug', action='store_true', help='å¯ç”¨è°ƒè¯•æ¨¡å¼')
    parser.add_argument('--verbose', action='store_true', help='å¯ç”¨è¯¦ç»†æ—¥å¿—æ¨¡å¼')
    parser.add_argument('--log-file', default='news_credibility.log', help='æ—¥å¿—æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--no-ai', action='store_true', help='ç¦ç”¨AIæœåŠ¡')
    parser.add_argument('--test', action='store_true', help='è¿è¡ŒåŠŸèƒ½æµ‹è¯•')
    parser.add_argument('--test-deepseek', action='store_true', help='æµ‹è¯•DeepSeek APIè¿æ¥')
    parser.add_argument('--quick', action='store_true', help='å¿«é€Ÿæ¨¡å¼ï¼Œè·³è¿‡DeepSeek APIåˆ†æ')
    parser.add_argument('--save', action='store_true', help='ä¿å­˜æ–°é—»åˆ°æœ¬åœ°æ–‡ä»¶å¤¹')
    parser.add_argument('--save-dir', default='saved_news', help='ä¿å­˜æ–°é—»çš„æ–‡ä»¶å¤¹è·¯å¾„')
    return parser.parse_args()

def get_rating_emoji(score):
    """æ ¹æ®è¯„åˆ†è¿”å›å¯¹åº”çš„emojiå’Œè¯„çº§"""
    if score >= 0.8:
        return "ğŸŒŸğŸŒŸğŸŒŸğŸŒŸ", "ä¼˜"
    elif score >= 0.7:
        return "ğŸŒŸğŸŒŸğŸŒŸ", "è‰¯"
    elif score >= 0.6:
        return "ğŸŒŸğŸŒŸ", "ä¸­"
    elif score >= 0.5:
        return "ğŸŒŸ", "ä¸€èˆ¬"
    else:
        return "â—", "å·®"

def get_progress_bar(score, width=10):
    """ç”Ÿæˆè¿›åº¦æ¡"""
    filled = int(score * width)
    return f"{'â–ˆ' * filled}{'â–‘' * (width - filled)}"

def get_credibility_rating(score):
    """æ ¹æ®å¯ä¿¡åº¦è¯„åˆ†è¿”å›è¯„çº§"""
    if score >= 0.8:
        return "é«˜åº¦å¯ä¿¡ ğŸŒŸğŸŒŸğŸŒŸğŸŒŸ", "é«˜"
    elif score >= 0.6:
        return "éƒ¨åˆ†å¯ä¿¡ ğŸŒŸğŸŒŸ", "ä¸­"
    elif score >= 0.4:
        return "ä½åº¦å¯ä¿¡ ğŸŒŸ", "ä½" 
    else:
        return "ä¸å¯ä¿¡ â—", "æä½"

def print_formatted_result(result):
    """æ ¼å¼åŒ–æ‰“å°åˆ†æç»“æœ"""
    total_score = result["æ€»ä½“è¯„åˆ†"]
    rating_text, rating_level = get_credibility_rating(total_score)
    rating_emoji, short_rating = get_rating_emoji(total_score)
    
    # å®šä¹‰æƒé‡æ˜¾ç¤º
    weights_for_display = {
        "ai_content": f"(æƒé‡: {DEFAULT_WEIGHTS['ai_content'] * 100:.0f}%)",
        "language_neutrality": f"(æƒé‡: {DEFAULT_WEIGHTS['language_neutrality'] * 100:.0f}%)",
        "source_citation_quality": f"(æƒé‡: {DEFAULT_WEIGHTS['source_citation_quality'] * 100:.0f}%)",
        "deepseek_analysis": f"(æƒé‡: {DEFAULT_WEIGHTS['deepseek_analysis'] * 100:.0f}%)",
        "cross_validation": f"(æƒé‡: {DEFAULT_WEIGHTS['cross_validation'] * 100:.0f}%)"
    }
    
    header = f"""
â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“
                     ğŸ“Š æ–°é—»å¯ä¿¡åº¦åˆ†æç»“æœ ğŸ“Š                       
======================================================================
â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“"""
    print(header)
    
    # è¾“å‡ºè­¦å‘Šä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
    if "è­¦å‘Š" in result and result["è­¦å‘Š"]:
        print(f"\n{Fore.YELLOW}âš ï¸ ç³»ç»Ÿè­¦å‘Š:{Style.RESET_ALL}")
        for warning in result["è­¦å‘Š"]:
            print(f"{Fore.YELLOW} â€¢ {warning}{Style.RESET_ALL}")
        print("----------------------------------------------------------------------")
    
    # è¾“å‡ºæ€»ä½“è¯„åˆ†å’Œè¯„çº§
    score_percentage = int(total_score * 100)
    progress_bar = get_progress_bar(total_score)
    
    print(f"""
                       æ€»ä½“å¯ä¿¡åº¦è¯„çº§: {rating_text}                       
                        æ€»åˆ†: {score_percentage}%                         
                    {get_credibility_summary(total_score)}
    """)
    
    # è¾“å‡ºè¯¦ç»†è¯„åˆ†
    print(f"{'=' * 50}")
    print(f"{Fore.CYAN}ã€è¯¦ç»†è¯„åˆ†ã€‘{Style.RESET_ALL}")
    print(f"{'-' * 50}")
    
    # æŒ‰é¡ºåºè¾“å‡ºå„é¡¹è¯„åˆ†
    score_items = [
        ("AIå†…å®¹æ£€æµ‹", "AIå†…å®¹æ£€æµ‹æ˜¯å¦ä¸ºäººç±»æ’°å†™", "ai_content"),
        ("è¯­è¨€ä¸­ç«‹æ€§", "è¯­è¨€æ˜¯å¦ä¸­ç«‹å®¢è§‚", "language_neutrality"),
        ("æ¥æºå¼•ç”¨è´¨é‡", "æ¥æºå’Œå¼•ç”¨çš„è´¨é‡", "source_citation_quality"),
        ("DeepSeekç»¼åˆåˆ†æ", "AIæ·±åº¦åˆ†æçš„ç»“æœ", "deepseek_analysis"),
        ("äº¤å‰éªŒè¯", "äº‹å®äº¤å‰éªŒè¯ç»“æœ", "cross_validation")
    ]
    
    for display_name, description, key_name in score_items:
        if display_name in result["å„é¡¹è¯„åˆ†"]:
            score = result["å„é¡¹è¯„åˆ†"][display_name]
            weight = weights_for_display.get(key_name, "")
            progress = get_progress_bar(score)
            
            # æ ¹æ®è¯„åˆ†ç»™ä¸åŒé¢œè‰²
            color = Fore.RED
            if score >= 0.8:
                color = Fore.GREEN
            elif score >= 0.6:
                color = Fore.CYAN
            elif score >= 0.4:
                color = Fore.YELLOW
                
            score_percentage = int(score * 100)
            print(f"{color}{display_name}{Style.RESET_ALL} ({description}): {score_percentage}% {progress} {weight}")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ç¼ºå¤±çš„è¯„åˆ†é¡¹
    missing_scores = result.get("ç¼ºå¤±è¯„åˆ†é¡¹", [])
    if missing_scores:
        print(f"\n{Fore.RED}è­¦å‘Š: ä»¥ä¸‹è¯„åˆ†é¡¹ç›®ç¼ºå¤±ï¼Œæœªå‚ä¸è®°åˆ†: {', '.join(missing_scores)}{Fore.RESET}")
        print(f"{Fore.YELLOW}æ³¨æ„: å…¶ä»–é¡¹ç›®çš„æƒé‡å·²ç­‰æ¯”ä¾‹æé«˜ä»¥å¼¥è¡¥ç¼ºå¤±é¡¹{Fore.RESET}")
    elif missing_scores:
        print(f"\nè­¦å‘Š: ä»¥ä¸‹è¯„åˆ†é¡¹ç›®ç¼ºå¤±ï¼Œæœªå‚ä¸è®°åˆ†: {', '.join(missing_scores)}")
        print(f"æ³¨æ„: å…¶ä»–é¡¹ç›®çš„æƒé‡å·²ç­‰æ¯”ä¾‹æé«˜ä»¥å¼¥è¡¥ç¼ºå¤±é¡¹")
    
    # å‡†å¤‡AIåˆ†ææ•°æ®
    ai_analysis_data = {}
    ai_detailed_scores = {}
    ai_category_scores = {}
    
    if "AIåˆ†æ" in result and isinstance(result["AIåˆ†æ"], dict) and "è¯¦ç»†åˆ†æ" in result["AIåˆ†æ"]:
        ai_analysis = result["AIåˆ†æ"]["è¯¦ç»†åˆ†æ"]
        
        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æä¸ºJSON
        if isinstance(ai_analysis, str):
            try:
                import json
                ai_analysis = json.loads(ai_analysis)
            except:
                ai_analysis = {}
        
        # æå–å„å¤§ç±»è¯„åˆ†å’Œç»†åˆ†ç‚¹è¯„åˆ†
        if isinstance(ai_analysis, dict):
            if "å„å¤§ç±»è¯„åˆ†" in ai_analysis:
                ai_category_scores = ai_analysis["å„å¤§ç±»è¯„åˆ†"]
            if "ç»†åˆ†ç‚¹è¯„åˆ†" in ai_analysis:
                ai_detailed_scores = ai_analysis["ç»†åˆ†ç‚¹è¯„åˆ†"]
    
    # åˆå¹¶æœ¬åœ°è¯„åˆ†å’ŒAIè¯„åˆ†ï¼Œç¡®ä¿åŒ…å«æ‰€æœ‰æŒ‡å®šçš„å¤§é¡¹
    combined_scores = {}
    
    # 1. æ·»åŠ å·²æœ‰çš„æœ¬åœ°è¯„åˆ†é¡¹
    for key, value in result.get("å„é¡¹è¯„åˆ†", {}).items():
        combined_scores[key] = value
    
    # 2. æ·»åŠ AIåˆ†æä¸­çš„å¤§ç±»è¯„åˆ†ï¼ˆå¦‚æœä¸åœ¨æœ¬åœ°è¯„åˆ†ä¸­ï¼‰
    for key, value in ai_category_scores.items():
        if key not in combined_scores:
            combined_scores[key] = value
    
    # 3. ç¡®ä¿åŒ…å«æ‰€æœ‰æŒ‡å®šçš„å¤§é¡¹
    required_categories = [
        "AIå†…å®¹æ£€æµ‹", "è¯­è¨€ä¸­ç«‹æ€§", "æ¥æºå’Œå¼•ç”¨è´¨é‡", "äº¤å‰éªŒè¯", 
        "å†…å®¹çœŸå®æ€§", "ä¿¡æ¯å‡†ç¡®æ€§", "æ¥æºå¯é æ€§", "é€»è¾‘è¿è´¯æ€§"
    ]
    
    # æ˜ å°„AIåˆ†æä¸­çš„ç±»åˆ«åˆ°æœ¬åœ°ç±»åˆ«
    ai_to_local_mapping = {
        "å†…å®¹çœŸå®æ€§": "AIå†…å®¹æ£€æµ‹",
        "è¯­è¨€å®¢è§‚æ€§": "è¯­è¨€ä¸­ç«‹æ€§",
        "æ¥æºå¯é æ€§": "æ¥æºå’Œå¼•ç”¨è´¨é‡",
        "å¼•ç”¨è´¨é‡": "æ¥æºå’Œå¼•ç”¨è´¨é‡"
    }
    
    # ç¡®ä¿æ‰€æœ‰å¿…éœ€ç±»åˆ«éƒ½å­˜åœ¨
    for category in required_categories:
        if category not in combined_scores:
            # å°è¯•ä»AIåˆ†æä¸­æ‰¾åˆ°å¯¹åº”é¡¹
            found = False
            for ai_cat, local_cat in ai_to_local_mapping.items():
                if local_cat == category and ai_cat in ai_category_scores:
                    combined_scores[category] = ai_category_scores[ai_cat]
                    found = True
                    break
            
            # å¦‚æœä»æœªæ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤å€¼
            if not found:
                combined_scores[category] = 0.5
    
    # è¯¦ç»†è¯„åˆ†è¡¨æ ¼
    if colorama_available:
        print(f"\n{Fore.MAGENTA}ğŸ“‹ äº‹å®æ ¸æŸ¥è¯„åˆ†{Style.RESET_ALL}")
        print(f"{Fore.MAGENTA}â”{Style.RESET_ALL}" * 70)
        print(f"{Fore.BLUE}è¯„åˆ†é¡¹ç›®                      å¾—åˆ†         è¯„çº§              {Style.RESET_ALL}")
        print(f"{Fore.MAGENTA}â”{Style.RESET_ALL}" * 70)
    else:
        print("\nğŸ“‹ äº‹å®æ ¸æŸ¥è¯„åˆ†")
        print("â”" * 70)
        print(f"è¯„åˆ†é¡¹ç›®                      å¾—åˆ†         è¯„çº§              ")
        print("â”" * 70)
    
    # æ‰“å°åˆå¹¶åçš„è¯„åˆ†é¡¹ç›®
    for key in required_categories:
        if key in combined_scores:
            value = combined_scores[key]
            emoji, rating = get_rating_emoji(value)
            progress = get_progress_bar(value)
            
            if colorama_available:
                # æ ¹æ®è¯„åˆ†è®¾ç½®é¢œè‰²
                if value >= 0.8:
                    color = Fore.GREEN
                elif value >= 0.6:
                    color = Fore.CYAN
                elif value >= 0.4:
                    color = Fore.YELLOW
                else:
                    color = Fore.RED
                print(f"{Fore.MAGENTA}{key:25} {color}{value:.1f} {rating:5} {progress:10}{Style.RESET_ALL}")
            else:
                print(f"{key:25} {value:.1f} {rating:5} {progress:10}")
    
    print(f"{Fore.MAGENTA}â”{Style.RESET_ALL}" * 70)
    
    # æ‰“å°å„é¡¹è¯„åˆ†çš„è¯¦ç»†æ‰“åˆ†ç‚¹
    if "è¯„åˆ†è¯¦æƒ…" in result or ai_detailed_scores:
        if colorama_available:
            print(f"\n{Fore.MAGENTA}ğŸ“Š è¯„åˆ†é¡¹ç›®è¯¦ç»†åˆ†æ{Style.RESET_ALL}")
        else:
            print("\nğŸ“Š è¯„åˆ†é¡¹ç›®è¯¦ç»†åˆ†æ")
        
        # å®šä¹‰æ¯ä¸ªå¤§é¡¹çš„æ‰“åˆ†ç‚¹
        scoring_details = {
            "AIå†…å®¹æ£€æµ‹": [
                "å¥å¼ç»“æ„åˆ†æ", "é‡å¤æ¨¡å¼æ£€æµ‹", "å¸¸è§AIè¡¨è¾¾æ–¹å¼è¯†åˆ«", "è¯æ±‡å¤šæ ·æ€§è¯„ä¼°", "è¯­è¨€è¿è´¯æ€§"
            ],
            "è¯­è¨€ä¸­ç«‹æ€§": [
                "æƒ…æ„Ÿè¯æ±‡åˆ†æ", "åè§è¯æ±‡æ£€æµ‹", "ä¿®è¾æ‰‹æ³•è¯„ä¼°", "å¹³è¡¡æŠ¥é“åˆ†æ", "è¯­è¨€å®¢è§‚æ€§"
            ],
            "æ¥æºå’Œå¼•ç”¨è´¨é‡": [
                "æ¥æºå¯é æ€§", "å¼•ç”¨å‡†ç¡®æ€§", "å¼•ç”¨å¤šæ ·æ€§", "å¼•ç”¨ç›¸å…³æ€§", "å¼•ç”¨æ—¶æ•ˆæ€§"
            ],
            "äº¤å‰éªŒè¯": [
                "å…³é”®ä¿¡æ¯éªŒè¯", "äº‹å®ä¸€è‡´æ€§", "å¤šæºæ¯”å¯¹", "æœç´¢ç»“æœç›¸å…³æ€§", "éªŒè¯è¦†ç›–ç‡"
            ],
            "å†…å®¹çœŸå®æ€§": [
                "äº‹å®æ ¸æŸ¥", "è™šæ„æˆåˆ†", "æ—¶é—´å‡†ç¡®æ€§", "åœ°ç‚¹å‡†ç¡®æ€§", "äººç‰©çœŸå®æ€§"
            ],
            "ä¿¡æ¯å‡†ç¡®æ€§": [
                "æ•°æ®å‡†ç¡®æ€§", "ç»†èŠ‚ä¸€è‡´æ€§", "ä¸“ä¸šæœ¯è¯­", "èƒŒæ™¯ä¿¡æ¯", "å¼•ç”¨å‡†ç¡®æ€§"
            ],
            "æ¥æºå¯é æ€§": [
                "ä¿¡æ¯æ¥æº", "æ¥æºæƒå¨æ€§", "å¤šæºéªŒè¯", "å¼•ç”¨è§„èŒƒ", "æ¥æºé€æ˜åº¦"
            ],
            "é€»è¾‘è¿è´¯æ€§": [
                "å› æœå…³ç³»", "è®ºè¯å®Œæ•´æ€§", "ç»“æ„æ¸…æ™°", "æ¨ç†åˆç†", "é€»è¾‘ä¸€è‡´æ€§"
            ]
        }
        
        # è·å–è¯¦ç»†è¯„åˆ†æ•°æ®
        detailed_scores = result.get("è¯„åˆ†è¯¦æƒ…", {})
        
        # æ‰“å°æ¯ä¸ªå¤§é¡¹çš„è¯¦ç»†æ‰“åˆ†ç‚¹
        for category in required_categories:
            if category in combined_scores:
                category_score = combined_scores[category]
                
                if colorama_available:
                    category_color = Fore.GREEN if category_score >= 0.8 else (Fore.CYAN if category_score >= 0.6 else (Fore.YELLOW if category_score >= 0.4 else Fore.RED))
                    print(f"\n{Fore.BLUE}ã€{category}ã€‘{Style.RESET_ALL} æ€»è¯„åˆ†: {category_color}{category_score:.2f}{Style.RESET_ALL}")
                    print(f"{Fore.BLUE}{'â”€' * 50}{Style.RESET_ALL}")
                else:
                    print(f"\nã€{category}ã€‘ æ€»è¯„åˆ†: {category_score:.2f}")
                    print("â”€" * 50)
                
                # æ‰“å°è¯¥å¤§é¡¹çš„å„ä¸ªæ‰“åˆ†ç‚¹
                if category in scoring_details:
                    for point in scoring_details[category]:
                        point_key = f"{category}_{point}"
                        point_score = detailed_scores.get(point_key, 0.0)
                        
                        # æŸ¥æ‰¾AIåˆ†æä¸­å¯¹åº”çš„æ‰“åˆ†ç‚¹
                        ai_point_key = None
                        if category == "AIå†…å®¹æ£€æµ‹":
                            ai_point_key = f"å†…å®¹çœŸå®æ€§_{point}"
                        elif category == "è¯­è¨€ä¸­ç«‹æ€§":
                            ai_point_key = f"è¯­è¨€å®¢è§‚æ€§_{point}"
                        elif category == "æ¥æºå’Œå¼•ç”¨è´¨é‡":
                            if point == "æ¥æºå¯é æ€§":
                                ai_point_key = f"æ¥æºå¯é æ€§_ä¿¡æ¯æ¥æº"
                            elif point in ["å¼•ç”¨å‡†ç¡®æ€§", "å¼•ç”¨å¤šæ ·æ€§", "å¼•ç”¨ç›¸å…³æ€§", "å¼•ç”¨æ—¶æ•ˆæ€§"]:
                                ai_point_key = f"å¼•ç”¨è´¨é‡_{point}"
                        elif category in ["å†…å®¹çœŸå®æ€§", "ä¿¡æ¯å‡†ç¡®æ€§", "æ¥æºå¯é æ€§", "é€»è¾‘è¿è´¯æ€§"]:
                            ai_point_key = f"{category}_{point}"
                        
                        # å¦‚æœæ‰¾åˆ°å¯¹åº”çš„AIæ‰“åˆ†ç‚¹ï¼ŒæŒ‰æƒé‡åˆå¹¶
                        if ai_point_key and ai_point_key in ai_detailed_scores:
                            ai_point_score = ai_detailed_scores[ai_point_key]
                            if point_score == 0.0:  # å¦‚æœæœ¬åœ°è¯„åˆ†ä¸å­˜åœ¨ï¼Œç›´æ¥ä½¿ç”¨AIè¯„åˆ†
                                point_score = ai_point_score
                            else:  # å¦åˆ™æŒ‰ç…§æƒé‡åˆå¹¶
                                # æŒ‰ç…§DEEPSEEK_WEIGHTSæƒé‡åˆå¹¶
                                combined_score = point_score * DEEPSEEK_WEIGHTS["local_algorithm"] + ai_point_score * DEEPSEEK_WEIGHTS["deepseek_algorithm"]
                                point_score = round(combined_score, 2)
                        elif point_score == 0.0:
                            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å¯¹åº”çš„AIæ‰“åˆ†ç‚¹ï¼Œä¸”æœ¬åœ°è¯„åˆ†ä¸å­˜åœ¨ï¼Œä½¿ç”¨ç±»åˆ«è¯„åˆ†
                            point_score = round(category_score, 2)
                        
                        if colorama_available:
                            point_color = Fore.GREEN if point_score >= 0.8 else (Fore.CYAN if point_score >= 0.6 else (Fore.YELLOW if point_score >= 0.4 else Fore.RED))
                            progress = get_progress_bar(point_score, width=8)
                            print(f"  {Fore.MAGENTA}â€¢ {point:20}: {point_color}{point_score:.2f} {progress}{Style.RESET_ALL}")
                        else:
                            progress = get_progress_bar(point_score, width=8)
                            print(f"  â€¢ {point:20}: {point_score:.2f} {progress}")
    
    # æ˜¾ç¤ºå¯ä¿¡åº¦åˆ¤æ–­çš„ç–‘ç‚¹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if "AIåˆ†æ" in result and isinstance(result["AIåˆ†æ"], dict) and "è¯¦ç»†åˆ†æ" in result["AIåˆ†æ"]:
        ai_analysis = result["AIåˆ†æ"]["è¯¦ç»†åˆ†æ"]
        
        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æä¸ºJSON
        if isinstance(ai_analysis, str):
            try:
                import json
                ai_analysis = json.loads(ai_analysis)
            except:
                ai_analysis = {}
        
        # æå–å¯ä¿¡åº¦åˆ¤æ–­çš„ç–‘ç‚¹
        if isinstance(ai_analysis, dict) and "å¯ä¿¡åº¦åˆ¤æ–­çš„ç–‘ç‚¹" in ai_analysis:
            if colorama_available:
                print(f"\n{Fore.MAGENTA}å¯ä¿¡åº¦ç–‘ç‚¹:{Style.RESET_ALL}")
            else:
                print(f"\nå¯ä¿¡åº¦ç–‘ç‚¹:")
                
            ç–‘ç‚¹æ–‡æœ¬ = ai_analysis['å¯ä¿¡åº¦åˆ¤æ–­çš„ç–‘ç‚¹']
            if isinstance(ç–‘ç‚¹æ–‡æœ¬, str):
                # å°è¯•åˆ†å‰²ç–‘ç‚¹æ–‡æœ¬
                if ";" in ç–‘ç‚¹æ–‡æœ¬ or "ï¼›" in ç–‘ç‚¹æ–‡æœ¬:
                    ç–‘ç‚¹åˆ—è¡¨ = re.split(r'[;ï¼›]', ç–‘ç‚¹æ–‡æœ¬)
                    for i, ç–‘ç‚¹ in enumerate(ç–‘ç‚¹åˆ—è¡¨, 1):
                        if ç–‘ç‚¹.strip():
                            if colorama_available:
                                print(f"  {Fore.YELLOW}{i}. {ç–‘ç‚¹.strip()}{Style.RESET_ALL}")
                            else:
                                print(f"  {i}. {ç–‘ç‚¹.strip()}")
                elif "," in ç–‘ç‚¹æ–‡æœ¬ or "ï¼Œ" in ç–‘ç‚¹æ–‡æœ¬:
                    ç–‘ç‚¹åˆ—è¡¨ = re.split(r'[,ï¼Œ]', ç–‘ç‚¹æ–‡æœ¬)
                    for i, ç–‘ç‚¹ in enumerate(ç–‘ç‚¹åˆ—è¡¨, 1):
                        if ç–‘ç‚¹.strip():
                            if colorama_available:
                                print(f"  {Fore.YELLOW}{i}. {ç–‘ç‚¹.strip()}{Style.RESET_ALL}")
                            else:
                                print(f"  {i}. {ç–‘ç‚¹.strip()}")
                else:
                    if colorama_available:
                        print(f"  {Fore.YELLOW}â€¢ {ç–‘ç‚¹æ–‡æœ¬}{Style.RESET_ALL}")
                    else:
                        print(f"  â€¢ {ç–‘ç‚¹æ–‡æœ¬}")
            else:
                if colorama_available:
                    print(f"  {Fore.YELLOW}â€¢ {ç–‘ç‚¹æ–‡æœ¬}{Style.RESET_ALL}")
                else:
                    print(f"  â€¢ {ç–‘ç‚¹æ–‡æœ¬}")
    
    # äº¤å‰éªŒè¯éƒ¨åˆ†
    if "äº¤å‰éªŒè¯" in result:
        if "æ€»ä½“å¯ä¿¡åº¦" not in result["äº¤å‰éªŒè¯"]:
            if colorama_available:
                print(f"\n{Fore.RED}é”™è¯¯: äº¤å‰éªŒè¯ç»“æœä¸­ç¼ºå°‘æ€»ä½“å¯ä¿¡åº¦{Style.RESET_ALL}")
            else:
                print("\né”™è¯¯: äº¤å‰éªŒè¯ç»“æœä¸­ç¼ºå°‘æ€»ä½“å¯ä¿¡åº¦")
        else:
            if colorama_available:
                print(f"\n{Fore.MAGENTA}ğŸ” äº¤å‰éªŒè¯ç»“æœ{Style.RESET_ALL}")
            else:
                print("\nğŸ” äº¤å‰éªŒè¯ç»“æœ")
            print(f"{Fore.MAGENTA}â”{Style.RESET_ALL}" * 70)
            
            # æ˜¾ç¤ºäº¤å‰éªŒè¯æ€»ä½“å¯ä¿¡åº¦
            cross_validation = result["äº¤å‰éªŒè¯"]
            cross_validation_score = cross_validation.get("æ€»ä½“å¯ä¿¡åº¦", 0.5)
            
            if colorama_available:
                score_color = Fore.GREEN if cross_validation_score >= 0.7 else (Fore.YELLOW if cross_validation_score >= 0.5 else Fore.RED)
                print(f"\n{Fore.BLUE}äº¤å‰éªŒè¯æ€»ä½“å¯ä¿¡åº¦: {score_color}{cross_validation_score:.2f}{Style.RESET_ALL}")
                if "éªŒè¯ç»“è®º" in cross_validation:
                    print(f"{Fore.MAGENTA}{score_color}{cross_validation.get('éªŒè¯ç»“è®º', '')}{Style.RESET_ALL}")
            else:
                print(f"\näº¤å‰éªŒè¯æ€»ä½“å¯ä¿¡åº¦: {cross_validation_score:.2f}")
                if "éªŒè¯ç»“è®º" in cross_validation:
                    print(f"{cross_validation.get('éªŒè¯ç»“è®º', '')}")
    elif "äº¤å‰éªŒè¯" in missing_scores and colorama_available:
        print(f"\n{Fore.RED}äº¤å‰éªŒè¯: ç¼ºå¤± (æœªå‚ä¸è®°åˆ†){Style.RESET_ALL}")
    elif "äº¤å‰éªŒè¯" in missing_scores:
        print(f"\näº¤å‰éªŒè¯: ç¼ºå¤± (æœªå‚ä¸è®°åˆ†)")
    
    # æ‰“å°é—®é¢˜åˆ—è¡¨
    if "é—®é¢˜" in result and result["é—®é¢˜"]:
        if colorama_available:
            print(f"\n{Fore.MAGENTA}âš ï¸ æ½œåœ¨é—®é¢˜{Style.RESET_ALL}")
            print(f"{Fore.MAGENTA}{'â”€' * 50}{Style.RESET_ALL}")
            for i, issue in enumerate(result["é—®é¢˜"], 1):
                print(f"{Fore.YELLOW}{i}. {issue}{Style.RESET_ALL}")
        else:
            print("\nâš ï¸ æ½œåœ¨é—®é¢˜")
            print("â”€" * 50)
            for i, issue in enumerate(result["é—®é¢˜"], 1):
                print(f"{i}. {issue}")
    
    # æ‰“å°æ–°é—»ä»·å€¼åˆ†æ
    """ 
    if "æ–°é—»ä»·å€¼åˆ†æ" in result and "æ€»åˆ†" in result["æ–°é—»ä»·å€¼åˆ†æ"]:
        news_value_score = result["æ–°é—»ä»·å€¼åˆ†æ"]["æ€»åˆ†"]
        if colorama_available:
            value_color = Fore.GREEN if news_value_score >= 0.8 else (Fore.CYAN if news_value_score >= 0.6 else (Fore.YELLOW if news_value_score >= 0.4 else Fore.RED))
            print(f"\n{LEVEL1_COLOR}ğŸ“° æ–°é—»ä»·å€¼åˆ†æ{Style.RESET_ALL}")
            print(f"{LEVEL1_COLOR}{'â”€' * 50}{Style.RESET_ALL}")
            print(f"{LEVEL2_COLOR}æ€»ä½“è¯„åˆ†: {value_color}{news_value_score:.2f}{Style.RESET_ALL}")
            if "æ€»ä½“è¯„ä»·" in result["æ–°é—»ä»·å€¼åˆ†æ"]:
                print(f"{LEVEL3_COLOR}{value_color}{result['æ–°é—»ä»·å€¼åˆ†æ']['æ€»ä½“è¯„ä»·']}{Style.RESET_ALL}")
        else:
            print("\nğŸ“° æ–°é—»ä»·å€¼åˆ†æ")
            print("â”€" * 50)
            print(f"æ€»ä½“è¯„åˆ†: {news_value_score:.2f}")
            if "æ€»ä½“è¯„ä»·" in result["æ–°é—»ä»·å€¼åˆ†æ"]:
                print(f"{result['æ–°é—»ä»·å€¼åˆ†æ']['æ€»ä½“è¯„ä»·']}")
    """

def perform_cross_validation(text: str, ai_analysis: Dict[str, Any]) -> Dict[str, Any]:
    """
    æ‰§è¡Œäº¤å‰éªŒè¯ï¼Œç”±DeepSeekæå–éœ€è¦éªŒè¯çš„å†…å®¹ï¼Œä½¿ç”¨SearXNGæœç´¢ï¼Œç„¶åç”±DeepSeekåˆ¤æ–­
    
    å‚æ•°:
        text (str): æ–°é—»æ–‡æœ¬
        ai_analysis (Dict[str, Any]): DeepSeek AIåˆ†æç»“æœ
    
    è¿”å›:
        Dict[str, Any]: äº¤å‰éªŒè¯ç»“æœ
    """
    logger.info("å¼€å§‹æ‰§è¡Œäº¤å‰éªŒè¯")
    
    # åˆå§‹åŒ–ç»“æœ
    results = {
        "éªŒè¯é¡¹ç›®": [],
        "æ€»ä½“å¯ä¿¡åº¦": 0.0,
        "éªŒè¯ç»“è®º": ""
    }
    
    try:
        # 1. ä½¿ç”¨DeepSeekæå–éœ€è¦éªŒè¯çš„å†…å®¹
        verification_points = extract_verification_points_with_deepseek(text)
        if not verification_points:
            logger.info("æœªæ‰¾åˆ°éœ€è¦äº¤å‰éªŒè¯çš„å†…å®¹")
            return None
        
        # 2. å¯¹æ¯ä¸ªéªŒè¯ç‚¹è¿›è¡Œæœç´¢å’ŒéªŒè¯
        total_score = 0.0
        verified_count = 0
        
        for point in verification_points:
            # æ„å»ºæœç´¢æŸ¥è¯¢
            query = point["æœç´¢æŸ¥è¯¢"]
            logger.info(f"äº¤å‰éªŒè¯æŸ¥è¯¢: {query}")
            
            # ä½¿ç”¨SearXNGæœç´¢
            if SEARXNG_AVAILABLE:
                search_results = search_with_searxng(query, num_results=5)
                
                if search_results and "results" in search_results and search_results["results"]:
                    # æå–æœç´¢ç»“æœ
                    search_snippets = []
                    for result in search_results["results"][:5]:  # å–å‰5ä¸ªç»“æœ
                        title = result.get("title", "")
                        snippet = result.get("content", "")
                        url = result.get("url", "")
                        # é™åˆ¶æ‘˜è¦é•¿åº¦ä¸º500ä¸ªå­—ç¬¦
                        if len(snippet) > 500:
                            snippet = snippet[:500] + "..."
                        
                        search_snippets.append({
                            "æ ‡é¢˜": title,
                            "æ‘˜è¦": snippet,
                            "é“¾æ¥": url
                        })
                    
                    # ä½¿ç”¨DeepSeekåˆ¤æ–­æœç´¢ç»“æœä¸éªŒè¯ç‚¹çš„ä¸€è‡´æ€§
                    verification_result = verify_search_results_with_deepseek(
                        point["å†…å®¹"], 
                        point["è´¨ç–‘ç‚¹"], 
                        search_snippets
                    )
                    
                    # æ·»åŠ åˆ°éªŒè¯ç»“æœ
                    verification_item = {
                        "éªŒè¯å†…å®¹": point["å†…å®¹"],
                        "è´¨ç–‘ç‚¹": point["è´¨ç–‘ç‚¹"],
                        "æœç´¢æŸ¥è¯¢": query,
                        "é‡è¦æ€§": point.get("é‡è¦æ€§", "ä¸­"),
                        "æœç´¢ç»“æœæ•°é‡": len(search_results["results"]),
                        "éªŒè¯è¯„åˆ†": verification_result["è¯„åˆ†"],
                        "éªŒè¯ç»“è®º": verification_result["ç»“è®º"],
                        "æœç´¢ç»“æœæ‘˜è¦": search_snippets[:5]  # åªä¿ç•™å‰5ä¸ªç»“æœ
                    }
                    
                    results["éªŒè¯é¡¹ç›®"].append(verification_item)
                    
                    # ç´¯è®¡è¯„åˆ†
                    total_score += verification_result["è¯„åˆ†"]
                    verified_count += 1
                else:
                    # æœªæ‰¾åˆ°æœç´¢ç»“æœ
                    verification_item = {
                        "éªŒè¯å†…å®¹": point["å†…å®¹"],
                        "è´¨ç–‘ç‚¹": point["è´¨ç–‘ç‚¹"],
                        "æœç´¢æŸ¥è¯¢": query,
                        "é‡è¦æ€§": point.get("é‡è¦æ€§", "ä¸­"),
                        "æœç´¢ç»“æœæ•°é‡": 0,
                        "éªŒè¯è¯„åˆ†": 0.5,
                        "éªŒè¯ç»“è®º": "æœªæ‰¾åˆ°ç›¸å…³æœç´¢ç»“æœï¼Œæ— æ³•éªŒè¯"
                    }
                    
                    results["éªŒè¯é¡¹ç›®"].append(verification_item)
                    
                    # ä½¿ç”¨ä¸­ç­‰è¯„åˆ†
                    total_score += 0.5
                    verified_count += 1
            else:
                logger.warning("SearXNGæœç´¢ä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡Œäº¤å‰éªŒè¯")
                return None
        
        # 3. è®¡ç®—æ€»ä½“å¯ä¿¡åº¦
        if verified_count > 0:
            results["æ€»ä½“å¯ä¿¡åº¦"] = round(total_score / verified_count, 2)
            
            # æ·»åŠ éªŒè¯ç»“è®º
            if results["æ€»ä½“å¯ä¿¡åº¦"] >= 0.8:
                results["éªŒè¯ç»“è®º"] = "äº¤å‰éªŒè¯ç»“æœè¡¨æ˜æ–°é—»å†…å®¹é«˜åº¦å¯ä¿¡ï¼Œå¤šä¸ªå…³é”®ä¿¡æ¯ç‚¹å¾—åˆ°å¤–éƒ¨æ¥æºç¡®è®¤"
            elif results["æ€»ä½“å¯ä¿¡åº¦"] >= 0.6:
                results["éªŒè¯ç»“è®º"] = "äº¤å‰éªŒè¯ç»“æœè¡¨æ˜æ–°é—»å†…å®¹åŸºæœ¬å¯ä¿¡ï¼Œéƒ¨åˆ†å…³é”®ä¿¡æ¯å¾—åˆ°å¤–éƒ¨æ¥æºç¡®è®¤"
            elif results["æ€»ä½“å¯ä¿¡åº¦"] >= 0.4:
                results["éªŒè¯ç»“è®º"] = "äº¤å‰éªŒè¯ç»“æœè¡¨æ˜æ–°é—»å†…å®¹å¯ä¿¡åº¦ä¸€èˆ¬ï¼Œéƒ¨åˆ†ä¿¡æ¯æœªå¾—åˆ°å……åˆ†ç¡®è®¤"
            else:
                results["éªŒè¯ç»“è®º"] = "äº¤å‰éªŒè¯ç»“æœè¡¨æ˜æ–°é—»å†…å®¹å¯ä¿¡åº¦è¾ƒä½ï¼Œå¤šä¸ªå…³é”®ä¿¡æ¯æœªå¾—åˆ°å¤–éƒ¨æ¥æºç¡®è®¤"
        else:
            results["æ€»ä½“å¯ä¿¡åº¦"] = 0.5
            results["éªŒè¯ç»“è®º"] = "æœªèƒ½å®Œæˆäº¤å‰éªŒè¯ï¼Œæ— æ³•è¯„ä¼°å†…å®¹å¯ä¿¡åº¦"
        
        logger.info(f"äº¤å‰éªŒè¯å®Œæˆï¼Œæ€»ä½“å¯ä¿¡åº¦: {results['æ€»ä½“å¯ä¿¡åº¦']}")
        return results
        
    except Exception as e:
        logger.error(f"äº¤å‰éªŒè¯è¿‡ç¨‹å‡ºé”™: {e}")
        logger.error(traceback.format_exc())
        return None

def extract_verification_points_with_deepseek(text: str) -> List[Dict[str, Any]]:
    """
    ä½¿ç”¨DeepSeekä»æ–‡æœ¬ä¸­æå–éœ€è¦éªŒè¯çš„å…³é”®ç‚¹
    
    å‚æ•°:
        text (str): æ–°é—»æ–‡æœ¬
    
    è¿”å›:
        List[Dict[str, Any]]: éœ€è¦éªŒè¯çš„å…³é”®ç‚¹åˆ—è¡¨ï¼Œæ¯ä¸ªç‚¹åŒ…å«å†…å®¹ã€è´¨ç–‘ç‚¹å’Œæœç´¢æŸ¥è¯¢
    """
    try:
        # æ„å»ºæç¤º
        prompt = f"""
        ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–°é—»äº‹å®æ ¸æŸ¥ä¸“å®¶ï¼Œéœ€è¦å¯¹ä»¥ä¸‹æ–°é—»æ–‡æœ¬è¿›è¡Œè´¨ç–‘æ€§åˆ†æï¼Œå¹¶æå–éœ€è¦äº¤å‰éªŒè¯çš„å†…å®¹ã€‚
        
        è¯·ä»”ç»†é˜…è¯»ä»¥ä¸‹æ–°é—»æ–‡æœ¬ï¼Œæ‰¾å‡º3-5ä¸ªéœ€è¦é€šè¿‡æœç´¢å¼•æ“è¿›è¡Œäº¤å‰éªŒè¯çš„å…³é”®ä¿¡æ¯ç‚¹ã€‚è¿™äº›ä¿¡æ¯ç‚¹åº”è¯¥æ˜¯ï¼š
        1. å¯èƒ½å­˜åœ¨äº‰è®®æˆ–éœ€è¦æ ¸å®çš„äº‹å®æ€§é™ˆè¿°
        2. å¼•ç”¨çš„æ•°æ®ã€ç»Ÿè®¡æˆ–ç ”ç©¶ç»“æœ
        3. å¼•è¿°çš„ä¸“å®¶è§‚ç‚¹æˆ–è¨€è®º
        4. å¯èƒ½å­˜åœ¨åè§æˆ–è¯¯å¯¼çš„è¡¨è¿°
        
        æ–°é—»æ–‡æœ¬:
        {text}
        
        å¯¹äºæ¯ä¸ªéœ€è¦éªŒè¯çš„ä¿¡æ¯ç‚¹ï¼Œè¯·æä¾›ï¼š
        1. åŸæ–‡ä¸­çš„å…·ä½“å†…å®¹
        2. ä½ å¯¹è¯¥å†…å®¹çš„è´¨ç–‘ç‚¹ï¼ˆä¸ºä»€ä¹ˆéœ€è¦éªŒè¯ï¼‰
        3. ç”¨äºæœç´¢å¼•æ“çš„æœ€ä½³æœç´¢æŸ¥è¯¢ï¼ˆæ³¨æ„ï¼šè¿™ä¸ªæŸ¥è¯¢å°†è¢«ç›´æ¥å‘é€åˆ°æœç´¢å¼•æ“ï¼Œè¯·ä½¿ç”¨æœ‰æ„ä¹‰çš„çŸ­å¥è€Œä¸æ˜¯å•ä¸€è¯è¯­ã€‚ç¡®ä¿æŸ¥è¯¢åŒ…å«2-3ä¸ªå…³é”®çŸ­å¥ï¼Œèƒ½å¤Ÿç²¾ç¡®å®šä½ç›¸å…³ä¿¡æ¯ã€‚ä¸è¦ä½¿ç”¨é—®å¥ï¼Œä¸è¦åŒ…å«å¼•å·æˆ–ç‰¹æ®Šç¬¦å·ï¼Œåªæä¾›æœç´¢å…³é”®çŸ­å¥ï¼‰
        4. è¯¥ä¿¡æ¯ç‚¹çš„é‡è¦æ€§ï¼ˆé«˜/ä¸­/ä½ï¼‰
        
        è¯·ä»¥JSONæ ¼å¼è¿”å›ç»“æœï¼Œæ ¼å¼å¦‚ä¸‹:
        [
            {{
                "å†…å®¹": "éœ€è¦éªŒè¯çš„åŸæ–‡å†…å®¹",
                "è´¨ç–‘ç‚¹": "ä¸ºä»€ä¹ˆéœ€è¦éªŒè¯è¿™ä¸ªå†…å®¹",
                "æœç´¢æŸ¥è¯¢": "å…³é”®çŸ­å¥1 å…³é”®çŸ­å¥2 å…³é”®çŸ­å¥3",
                "é‡è¦æ€§": "é«˜/ä¸­/ä½"
            }},
            ...
        ]
        """
        
        # è°ƒç”¨DeepSeek API
        response = query_deepseek(prompt)
        
        # è§£æJSONå“åº”
        import json
        try:
            # å°è¯•ç›´æ¥è§£æ
            verification_points = json.loads(response)
        except json.JSONDecodeError:
            # å¦‚æœç›´æ¥è§£æå¤±è´¥ï¼Œå°è¯•æå–JSONéƒ¨åˆ†
            json_match = re.search(r'\[\s*\{.*\}\s*\]', response, re.DOTALL)
            if json_match:
                verification_points = json.loads(json_match.group(0))
            else:
                # å¦‚æœä»ç„¶å¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨
                logger.warning("æ— æ³•ä»DeepSeekå“åº”ä¸­æå–JSON")
                return []
        
        # éªŒè¯ç»“æœæ ¼å¼
        if isinstance(verification_points, list) and all(isinstance(item, dict) and "å†…å®¹" in item and "æœç´¢æŸ¥è¯¢" in item for item in verification_points):
            return verification_points
        else:
            logger.warning("DeepSeekè¿”å›çš„éªŒè¯ç‚¹æ ¼å¼ä¸æ­£ç¡®")
            return []
            
    except Exception as e:
        logger.error(f"ä½¿ç”¨DeepSeekæå–éªŒè¯ç‚¹æ—¶å‡ºé”™: {e}")
        return []

def verify_search_results_with_deepseek(content: str, doubt_point: str, search_results: List[Dict[str, str]]) -> Dict[str, Any]:
    """
    ä½¿ç”¨DeepSeekåˆ¤æ–­æœç´¢ç»“æœä¸éªŒè¯ç‚¹çš„ä¸€è‡´æ€§
    
    å‚æ•°:
        content (str): éœ€è¦éªŒè¯çš„å†…å®¹
        doubt_point (str): è´¨ç–‘ç‚¹
        search_results (List[Dict[str, str]]): æœç´¢ç»“æœåˆ—è¡¨
    
    è¿”å›:
        Dict[str, Any]: éªŒè¯ç»“æœ
    """
    try:
        # æ„å»ºæœç´¢ç»“æœæ–‡æœ¬
        search_text = ""
        for i, result in enumerate(search_results, 1):
            search_text += f"æœç´¢ç»“æœ{i}:\n"
            search_text += f"æ ‡é¢˜: {result.get('æ ‡é¢˜', '')}\n"
            search_text += f"æ‘˜è¦: {result.get('æ‘˜è¦', '')}\n"
            search_text += f"é“¾æ¥: {result.get('é“¾æ¥', '')}\n\n"
        
        # æ„å»ºæç¤º
        prompt = f"""
        ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–°é—»äº‹å®æ ¸æŸ¥ä¸“å®¶ï¼Œéœ€è¦å¯¹æ–°é—»ä¸­çš„ä¿¡æ¯ç‚¹è¿›è¡Œäº¤å‰éªŒè¯ã€‚
        
        éœ€è¦éªŒè¯çš„æ–°é—»å†…å®¹:
        "{content}"
        
        è´¨ç–‘ç‚¹:
        {doubt_point}
        
        æœç´¢ç»“æœ:
        {search_text}
        
        è¯·ä»”ç»†åˆ†ææœç´¢ç»“æœï¼Œåˆ¤æ–­å®ƒä»¬æ˜¯å¦æ”¯æŒã€éƒ¨åˆ†æ”¯æŒã€ä¸æ”¯æŒæˆ–ä¸æ–°é—»å†…å®¹çŸ›ç›¾ã€‚
        
        è¯„ä¼°è¦ç‚¹:
        1. æœç´¢ç»“æœæ˜¯å¦ç›´æ¥æˆ–é—´æ¥è¯å®/åé©³äº†æ–°é—»å†…å®¹
        2. æœç´¢ç»“æœçš„æ¥æºå¯é æ€§å’Œæƒå¨æ€§ï¼ˆå¦‚å®˜æ–¹ç½‘ç«™ã€çŸ¥ååª’ä½“ã€å­¦æœ¯æœºæ„ç­‰ï¼‰
        3. æœç´¢ç»“æœçš„æ—¶æ•ˆæ€§ï¼ˆæ˜¯å¦ä¸ºæœ€æ–°ä¿¡æ¯ï¼‰
        4. æœç´¢ç»“æœä¸æ–°é—»å†…å®¹çš„ä¸€è‡´ç¨‹åº¦ï¼ˆæ˜¯å¦æœ‰ç»†èŠ‚å·®å¼‚ï¼‰
        5. æ˜¯å¦æœ‰å¤šä¸ªç‹¬ç«‹æ¥æºæ”¯æŒ/åé©³æ–°é—»å†…å®¹
        
        è¯·ç»™å‡º0åˆ°1ä¹‹é—´çš„å¯ä¿¡åº¦è¯„åˆ†ï¼Œå…¶ä¸­:
        - 0.9-1.0: å¤šä¸ªå¯é æ¥æºå¼ºçƒˆæ”¯æŒè¯¥å†…å®¹ï¼Œç»†èŠ‚ä¸€è‡´
        - 0.7-0.9: è‡³å°‘ä¸€ä¸ªå¯é æ¥æºæ”¯æŒè¯¥å†…å®¹ï¼Œæ— æ˜æ˜¾çŸ›ç›¾
        - 0.5-0.7: æœç´¢ç»“æœéƒ¨åˆ†æ”¯æŒè¯¥å†…å®¹ï¼Œæˆ–æ”¯æŒä¸åå¯¹è¯æ®å‡è¡¡
        - 0.3-0.5: æœç´¢ç»“æœä¸å†…å®¹ç›¸å…³ä½†ä¸ç›´æ¥æ”¯æŒï¼Œæˆ–æœ‰ç»†èŠ‚å·®å¼‚
        - 0.0-0.3: æœç´¢ç»“æœä¸å†…å®¹çŸ›ç›¾æˆ–å¼ºçƒˆåå¯¹
        
        è¯·ä»¥JSONæ ¼å¼è¿”å›ç»“æœ:
        {{
            "è¯„åˆ†": 0.0-1.0ä¹‹é—´çš„æ•°å€¼,
            "ç»“è®º": "å¯¹å†…å®¹å¯ä¿¡åº¦çš„ç®€çŸ­è¯„ä¼°ï¼ˆ50å­—ä»¥å†…ï¼‰",
            "åˆ†æ": "è¯¦ç»†åˆ†ææœç´¢ç»“æœå¦‚ä½•æ”¯æŒæˆ–åå¯¹å†…å®¹ï¼ˆ200å­—ä»¥å†…ï¼‰"
        }}
        """
        
        # è°ƒç”¨DeepSeek API
        response = query_deepseek(prompt)
        
        # è§£æJSONå“åº”
        import json
        try:
            # å°è¯•ç›´æ¥è§£æ
            result = json.loads(response)
        except json.JSONDecodeError:
            # å¦‚æœç›´æ¥è§£æå¤±è´¥ï¼Œå°è¯•æå–JSONéƒ¨åˆ†
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                result = json.loads(json_match.group(0))
            else:
                # å¦‚æœä»ç„¶å¤±è´¥ï¼Œè¿”å›é»˜è®¤ç»“æœ
                logger.warning("æ— æ³•ä»DeepSeekå“åº”ä¸­æå–JSON")
                return {
                    "è¯„åˆ†": 0.5,
                    "ç»“è®º": "æ— æ³•è§£æéªŒè¯ç»“æœï¼Œä½¿ç”¨é»˜è®¤è¯„åˆ†",
                    "åˆ†æ": "DeepSeek APIè¿”å›çš„ç»“æœæ ¼å¼ä¸æ­£ç¡®"
                }
        
        # éªŒè¯ç»“æœæ ¼å¼
        if isinstance(result, dict) and "è¯„åˆ†" in result and "ç»“è®º" in result:
            # ç¡®ä¿è¯„åˆ†åœ¨0-1èŒƒå›´å†…
            result["è¯„åˆ†"] = max(0.0, min(1.0, float(result["è¯„åˆ†"])))
            return result
        else:
            logger.warning("DeepSeekè¿”å›çš„éªŒè¯ç»“æœæ ¼å¼ä¸æ­£ç¡®")
            return {
                "è¯„åˆ†": 0.5,
                "ç»“è®º": "éªŒè¯ç»“æœæ ¼å¼ä¸æ­£ç¡®ï¼Œä½¿ç”¨é»˜è®¤è¯„åˆ†",
                "åˆ†æ": "DeepSeek APIè¿”å›çš„ç»“æœç¼ºå°‘å¿…è¦å­—æ®µ"
            }
            
    except Exception as e:
        logger.error(f"ä½¿ç”¨DeepSeekéªŒè¯æœç´¢ç»“æœæ—¶å‡ºé”™: {e}")
        return {
            "è¯„åˆ†": 0.5,
            "ç»“è®º": f"éªŒè¯è¿‡ç¨‹å‡ºé”™: {str(e)}",
            "åˆ†æ": "åœ¨è°ƒç”¨DeepSeek APIè¿›è¡ŒéªŒè¯æ—¶å‘ç”Ÿé”™è¯¯"
        }

def save_news_to_local(text, url, result, save_dir, image_paths=None):
    """
    ä¿å­˜æ–°é—»åˆ°æœ¬åœ°æ–‡ä»¶å¤¹
    
    å‚æ•°:
        text: æ–°é—»æ–‡æœ¬
        url: æ–°é—»URL
        result: åˆ†æç»“æœ
        save_dir: ä¿å­˜ç›®å½•
        image_paths: å›¾ç‰‡è·¯å¾„åˆ—è¡¨
    """
    try:
        # åˆ›å»ºä¿å­˜ç›®å½•
        os.makedirs(save_dir, exist_ok=True)
        
        # ç”Ÿæˆæ—¶é—´æˆ³å’Œæ–‡ä»¶å
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        
        # ä»URLä¸­æå–åŸŸåä½œä¸ºæ–‡ä»¶åçš„ä¸€éƒ¨åˆ†
        domain = "unknown"
        if url:
            try:
                from urllib.parse import urlparse
                parsed_url = urlparse(url)
                domain = parsed_url.netloc.replace("www.", "").split(".")[0]
            except:
                pass
        
        base_filename = f"{timestamp}_{domain}"
        
        # ä¿å­˜æ–°é—»æ–‡æœ¬
        text_filename = os.path.join(save_dir, f"{base_filename}.txt")
        with open(text_filename, "w", encoding="utf-8") as f:
            f.write(f"URL: {url}\n\n")
            f.write(text)
        
        # ä¿å­˜åˆ†æç»“æœ
        result_filename = os.path.join(save_dir, f"{base_filename}_analysis.json")
        with open(result_filename, "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        # å¦‚æœæœ‰å›¾ç‰‡ï¼Œå¤åˆ¶åˆ°ä¿å­˜ç›®å½•
        if image_paths:
            # åˆ›å»ºå›¾ç‰‡å­ç›®å½•
            images_dir = os.path.join(save_dir, f"{base_filename}_images")
            os.makedirs(images_dir, exist_ok=True)
            
            # å¤åˆ¶å›¾ç‰‡
            for i, img_path in enumerate(image_paths):
                if os.path.exists(img_path):
                    # è·å–æ–‡ä»¶æ‰©å±•å
                    _, ext = os.path.splitext(img_path)
                    # å¤åˆ¶å›¾ç‰‡
                    import shutil
                    dest_path = os.path.join(images_dir, f"image_{i+1}{ext}")
                    shutil.copy2(img_path, dest_path)
        
        logger.info(f"æ–°é—»å·²ä¿å­˜åˆ°: {text_filename}")
        logger.info(f"åˆ†æç»“æœå·²ä¿å­˜åˆ°: {result_filename}")
        if image_paths:
            logger.info(f"å›¾ç‰‡å·²ä¿å­˜åˆ°: {images_dir}")
        
        return True
    except Exception as e:
        logger.error(f"ä¿å­˜æ–°é—»æ—¶å‡ºé”™: {e}")
        logger.error(traceback.format_exc())
        return False

def query_deepseek(prompt: str) -> str:
    """
    è°ƒç”¨DeepSeek APIè¿›è¡ŒæŸ¥è¯¢
    
    å‚æ•°:
        prompt (str): æç¤ºæ–‡æœ¬
    
    è¿”å›:
        str: DeepSeekçš„å“åº”æ–‡æœ¬
    """
    try:
        # æ£€æŸ¥APIå¯†é’¥æ˜¯å¦å¯ç”¨
        if not DEEPSEEK_API_KEY:
            logger.error("DeepSeek APIå¯†é’¥æœªè®¾ç½®")
            return ""
        
        # æ„å»ºè¯·æ±‚
        headers = {
            "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": "deepseek-chat",
            "messages": [
                {"role": "user", "content": prompt}
            ],
            "temperature": 0.3,  # è¾ƒä½çš„æ¸©åº¦ä»¥è·å¾—æ›´ç¡®å®šæ€§çš„å›ç­”
            "max_tokens": 2000
        }
        
        # å‘é€è¯·æ±‚
        response = requests.post(
            "https://api.deepseek.com/v1/chat/completions",
            headers=headers,
            json=data,
            timeout=30
        )
        
        # æ£€æŸ¥å“åº”
        if response.status_code == 200:
            result = response.json()
            if "choices" in result and len(result["choices"]) > 0:
                return result["choices"][0]["message"]["content"]
            else:
                logger.warning("DeepSeek APIè¿”å›çš„å“åº”æ ¼å¼ä¸æ­£ç¡®")
                return ""
        else:
            logger.error(f"DeepSeek APIè¯·æ±‚å¤±è´¥: {response.status_code} - {response.text}")
            return ""
            
    except Exception as e:
        logger.error(f"è°ƒç”¨DeepSeek APIæ—¶å‡ºé”™: {e}")
        return ""

def print_service_status(services_status):
    """
    æ‰“å°æœåŠ¡çŠ¶æ€å’Œå—å½±å“çš„åŠŸèƒ½
    
    å‚æ•°:
        services_status (dict): æœåŠ¡çŠ¶æ€å­—å…¸
    """
    print("\n" + "="*80)
    print(f"{Fore.CYAN}ã€ç³»ç»Ÿè‡ªæ£€ã€‘{Style.RESET_ALL}")
    print("-"*80)
    
    if services_status["deepseek_api"]:
        print(f"{Fore.GREEN}âœ“ DeepSeek API å¯ç”¨{Style.RESET_ALL}")
    else:
        print(f"{Fore.RED}âœ— DeepSeek API ä¸å¯ç”¨{Style.RESET_ALL}")
        print(f"  {Fore.YELLOW}â— å°†ä½¿ç”¨æœ¬åœ°ç®—æ³•è¿›è¡Œåˆ†æï¼Œç²¾åº¦å¯èƒ½å—é™{Style.RESET_ALL}")
    
    if services_status["searxng"]:
        print(f"{Fore.GREEN}âœ“ SearXNG æœç´¢å¼•æ“å¯ç”¨{Style.RESET_ALL}")
    else:
        print(f"{Fore.RED}âœ— SearXNG æœç´¢å¼•æ“ä¸å¯ç”¨{Style.RESET_ALL}")
        print(f"  {Fore.YELLOW}â— äº¤å‰éªŒè¯åŠŸèƒ½å°†å—é™{Style.RESET_ALL}")
    
    affected_features = services_status.get("affected_features", [])
    if affected_features:
        print("\n" + "-"*80)
        print(f"{Fore.YELLOW}ã€å—å½±å“çš„åŠŸèƒ½ã€‘{Style.RESET_ALL}")
        for service in affected_features:
            print(f"\n{Fore.RED}â— {service['service']} - {service['status']}{Style.RESET_ALL}")
            print(f"  {Fore.YELLOW}ä»¥ä¸‹åŠŸèƒ½å°†æ— æ³•ä½¿ç”¨æˆ–æ€§èƒ½ä¸‹é™:{Style.RESET_ALL}")
            for feature in service['affected_features']:
                print(f"  {Fore.YELLOW}â†’ {feature}{Style.RESET_ALL}")
    
    print("="*80 + "\n")

# å¦‚æœç›´æ¥è¿è¡Œæ­¤æ¨¡å—ï¼Œæ‰§è¡Œåˆå§‹åŒ–
if __name__ == "__main__":
    args = parse_arguments()
    
    # å¦‚æœç¦ç”¨AIæœåŠ¡ï¼Œè®¾ç½®ç¯å¢ƒå˜é‡
    if args.no_ai:
        os.environ['DISABLE_AI'] = 'true'
    
    # é…ç½®æ—¥å¿—çº§åˆ«
    debug_mode = args.debug
    verbose_mode = args.verbose or args.debug
    
    # ä½¿ç”¨utils.pyä¸­çš„setup_loggingå‡½æ•°
    from utils import setup_logging
    logger = setup_logging(log_file=args.log_file, debug=debug_mode, verbose=verbose_mode)
    
    # æ‰“å°å¯åŠ¨ä¿¡æ¯
    logger.info("æ–°é—»å¯ä¿¡åº¦åˆ†æå·¥å…·å¯åŠ¨")
    logger.info(f"è°ƒè¯•æ¨¡å¼: {'å¯ç”¨' if debug_mode else 'ç¦ç”¨'}")
    logger.info(f"è¯¦ç»†æ—¥å¿—: {'å¯ç”¨' if verbose_mode else 'ç¦ç”¨'}")
    logger.info(f"AIæœåŠ¡: {'ç¦ç”¨' if args.no_ai else 'å¯ç”¨'}")
    logger.info(f"å¿«é€Ÿæ¨¡å¼: {'å¯ç”¨' if args.quick else 'ç¦ç”¨'}")
    
    # å¦‚æœæ˜¯æµ‹è¯•æ¨¡å¼ï¼Œæ‰§è¡Œç®€å•æµ‹è¯•å¹¶é€€å‡º
    if args.test:
        from test_utils import simple_test
        simple_test()
        sys.exit(0)
    
    # å¦‚æœæ˜¯æµ‹è¯•DeepSeek APIè¿æ¥æ¨¡å¼ï¼Œæ‰§è¡Œæµ‹è¯•å¹¶é€€å‡º
    if args.test_deepseek:
        from ai_services import test_deepseek_connection
        result = test_deepseek_connection()
        if result:
            print("DeepSeek APIè¿æ¥æµ‹è¯•æˆåŠŸï¼âœ…")
        else:
            print("DeepSeek APIè¿æ¥æµ‹è¯•å¤±è´¥ï¼âŒ")
        sys.exit(0)
    
    # åˆå§‹åŒ–æœåŠ¡å¹¶æ˜¾ç¤ºæœåŠ¡çŠ¶æ€
    services_status = initialize_services()
    print_service_status(services_status)
    
    # è·å–åˆ†ææ–‡æœ¬
    analysis_text = None
    image_paths = []  # åˆå§‹åŒ–å›¾ç‰‡è·¯å¾„åˆ—è¡¨
    
    if args.url:
        try:
            # ä»URLè·å–å†…å®¹
            print(f"æ­£åœ¨ä»URLè·å–å†…å®¹: {args.url}")
            news_text, image_paths = fetch_news_content(args.url)
            if news_text:
                analysis_text = news_text
            else:
                print("æ— æ³•ä»URLè·å–å†…å®¹")
                sys.exit(1)
        except Exception as e:
            print(f"è·å–URLå†…å®¹æ—¶å‡ºé”™: {e}")
            sys.exit(1)
    else:
        # ä½¿ç”¨é»˜è®¤æµ‹è¯•æ–‡æœ¬
        analysis_text = """
        æ®å¯é æ¶ˆæ¯æ¥æºæŠ¥é“ï¼Œç§‘å­¦å®¶ä»¬æœ€è¿‘å‘ç°äº†ä¸€ç§æ–°å‹ææ–™ï¼Œå¯ä»¥æ˜¾è‘—æé«˜å¤ªé˜³èƒ½ç”µæ± çš„æ•ˆç‡ã€‚
        è¿™ç§ææ–™ç”±çŸ³å¢¨çƒ¯å’Œé’™é’›çŸ¿å¤åˆè€Œæˆï¼Œåœ¨å®éªŒå®¤æ¡ä»¶ä¸‹ï¼Œèƒ½å¤Ÿå°†å¤ªé˜³èƒ½è½¬åŒ–æ•ˆç‡æé«˜è‡³32%ï¼Œ
        è¿œé«˜äºç›®å‰å¸‚åœºä¸Š20-25%çš„å¹³å‡æ°´å¹³ã€‚ç ”ç©¶è´Ÿè´£äººå¼ æ•™æˆè¡¨ç¤ºï¼š"è¿™ä¸€çªç ´å¯èƒ½å½»åº•æ”¹å˜
        å¯å†ç”Ÿèƒ½æºè¡Œä¸šã€‚"å¤šä½è¡Œä¸šä¸“å®¶å¯¹æ­¤è¡¨ç¤ºè®¤å¯ï¼Œä½†ä¹ŸæŒ‡å‡ºä»å®éªŒå®¤åˆ°å•†ä¸šåŒ–è¿˜æœ‰å¾ˆé•¿çš„è·¯è¦èµ°ã€‚
        """
        print("æœªæä¾›URLï¼Œä½¿ç”¨é»˜è®¤æµ‹è¯•æ–‡æœ¬")
    
    # åˆ†ææ–°é—»å¯ä¿¡åº¦
    result = analyze_news_credibility(
        text=analysis_text,
        url=args.url if args.url else None,
        use_ai_services=not (args.no_ai or args.quick)  # å¿«é€Ÿæ¨¡å¼ä¸‹ä¹Ÿè·³è¿‡AIæœåŠ¡
    )
    
    # å¦‚æœæ˜¯å¿«é€Ÿæ¨¡å¼ï¼Œæ·»åŠ æ¨¡æ‹Ÿçš„AIåˆ†æç»“æœ
    if args.quick and not args.no_ai:
        result["AIåˆ†æ"] = {
            "è¯„åˆ†": 0.75,
            "è¯¦ç»†åˆ†æ": json.dumps({
                "æ€»ä½“è¯„åˆ†": 0.75,
                "å„å¤§ç±»è¯„åˆ†": {
                    "å†…å®¹çœŸå®æ€§": 0.78,
                    "ä¿¡æ¯å‡†ç¡®æ€§": 0.76,
                    "æ¥æºå¯é æ€§": 0.65,
                    "è¯­è¨€å®¢è§‚æ€§": 0.82,
                    "é€»è¾‘è¿è´¯æ€§": 0.80,
                    "å¼•ç”¨è´¨é‡": 0.70
                },
                "ç»†åˆ†ç‚¹è¯„åˆ†": {
                    "å†…å®¹çœŸå®æ€§_äº‹å®æ ¸æŸ¥": 0.75,
                    "å†…å®¹çœŸå®æ€§_è™šæ„æˆåˆ†": 0.80,
                    "å†…å®¹çœŸå®æ€§_æ—¶é—´å‡†ç¡®æ€§": 0.70,
                    "å†…å®¹çœŸå®æ€§_åœ°ç‚¹å‡†ç¡®æ€§": 0.85,
                    "å†…å®¹çœŸå®æ€§_äººç‰©çœŸå®æ€§": 0.80,
                    "ä¿¡æ¯å‡†ç¡®æ€§_æ•°æ®å‡†ç¡®æ€§": 0.75,
                    "ä¿¡æ¯å‡†ç¡®æ€§_ç»†èŠ‚ä¸€è‡´æ€§": 0.80,
                    "ä¿¡æ¯å‡†ç¡®æ€§_ä¸“ä¸šæœ¯è¯­": 0.85,
                    "ä¿¡æ¯å‡†ç¡®æ€§_èƒŒæ™¯ä¿¡æ¯": 0.65,
                    "æ¥æºå¯é æ€§_ä¿¡æ¯æ¥æº": 0.60,
                    "æ¥æºå¯é æ€§_æ¥æºæƒå¨æ€§": 0.65,
                    "æ¥æºå¯é æ€§_å¤šæºéªŒè¯": 0.60,
                    "æ¥æºå¯é æ€§_å¼•ç”¨è§„èŒƒ": 0.75,
                    "è¯­è¨€å®¢è§‚æ€§_æƒ…æ„Ÿè‰²å½©": 0.85,
                    "è¯­è¨€å®¢è§‚æ€§_åè§æ£€æµ‹": 0.80,
                    "è¯­è¨€å®¢è§‚æ€§_å¹³è¡¡æŠ¥é“": 0.75,
                    "è¯­è¨€å®¢è§‚æ€§_ä¿®è¾ä½¿ç”¨": 0.85,
                    "é€»è¾‘è¿è´¯æ€§_å› æœå…³ç³»": 0.80,
                    "é€»è¾‘è¿è´¯æ€§_è®ºè¯å®Œæ•´æ€§": 0.75,
                    "é€»è¾‘è¿è´¯æ€§_ç»“æ„æ¸…æ™°": 0.85,
                    "é€»è¾‘è¿è´¯æ€§_æ¨ç†åˆç†": 0.80,
                    "å¼•ç”¨è´¨é‡_å¼•ç”¨å¤šæ ·æ€§": 0.65,
                    "å¼•ç”¨è´¨é‡_å¼•ç”¨æ—¶æ•ˆæ€§": 0.70,
                    "å¼•ç”¨è´¨é‡_å¼•ç”¨ç›¸å…³æ€§": 0.75
                },
                "è¯¦ç»†åˆ†æ": "è¿™æ˜¯ä¸€ç¯‡å…³äºå¤ªé˜³èƒ½ç”µæ± æ–°ææ–™çš„ç§‘æŠ€æ–°é—»ï¼Œæ•´ä½“å¯ä¿¡åº¦è¾ƒé«˜ã€‚æ–°é—»æåˆ°äº†å…·ä½“çš„æ•ˆç‡æ•°æ®ï¼ˆ32%ï¼‰å’Œå¸‚åœºå¹³å‡æ°´å¹³ï¼ˆ20-25%ï¼‰ï¼Œå¢åŠ äº†å¯ä¿¡åº¦ã€‚å¼•ç”¨äº†ç ”ç©¶è´Ÿè´£äººå¼ æ•™æˆå’Œå¤šä½è¡Œä¸šä¸“å®¶çš„è§‚ç‚¹ï¼Œä½†æœªæä¾›å…·ä½“çš„ç ”ç©¶æœºæ„ã€å‘è¡¨æœŸåˆŠç­‰è¯¦ç»†ä¿¡æ¯ï¼Œé™ä½äº†æ¥æºå¯é æ€§ã€‚è¯­è¨€è¡¨è¿°å®¢è§‚ï¼Œé€»è¾‘ç»“æ„æ¸…æ™°ï¼Œä½†ç¼ºä¹å¤šæºéªŒè¯ã€‚",
                "å¯ä¿¡åº¦åˆ¤æ–­çš„ç–‘ç‚¹": "1. æœªæä¾›å…·ä½“ç ”ç©¶æœºæ„åç§°ï¼›2. æœªè¯´æ˜ç ”ç©¶å‘è¡¨åœ¨å“ªä¸ªæœŸåˆŠæˆ–ä¼šè®®ï¼›3. æœªæä¾›å…·ä½“çš„å®éªŒæ¡ä»¶å’Œæ–¹æ³•ï¼›4. 'å¤šä½è¡Œä¸šä¸“å®¶'è¡¨è¿°æ¨¡ç³Šï¼Œæœªå…·ä½“è¯´æ˜æ˜¯å“ªäº›ä¸“å®¶ã€‚"
            }, ensure_ascii=False)
        }
    
    # ä½¿ç”¨æ ¼å¼åŒ–æ‰“å°åŠŸèƒ½
    print_formatted_result(result)

    # å¦‚æœç”¨æˆ·æŒ‡å®šäº†ä¿å­˜æ–°é—»ï¼Œè°ƒç”¨save_news_to_localå‡½æ•°
    if args.save:
        if save_news_to_local(analysis_text, args.url, result, args.save_dir, image_paths):
            print(f"\næ–°é—»å·²ä¿å­˜åˆ°æ–‡ä»¶å¤¹: {os.path.abspath(args.save_dir)}")
        else:
            print("\nä¿å­˜æ–°é—»å¤±è´¥ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—äº†è§£è¯¦æƒ…ã€‚")
